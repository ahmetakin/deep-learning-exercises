{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce688751-ef6c-4a1c-a974-4d21a07ee0a6",
   "metadata": {},
   "source": [
    "# AutoEncoders\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f65a2c-476c-4fad-a6ed-47b1e21dd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e180547-c98d-49a0-9ac0-22cd768595a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb38003-7cda-4015-bf0c-e8b4ffcde369",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the training set and the test set\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781ff253-47cf-41ec-b5ab-1bb65e52ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8daf79a-794a-42d0-9354-e508e357fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the data into an array with users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef0e252-ab7f-4ed3-95b3-9d9fa218566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a871907-c3cd-4e53-a91f-29021324745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the architecture of the Neural Network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()#nn module methodlarını kullanmak için\n",
    "        #fc full connection\n",
    "        self.fc1 = nn.Linear(nb_movies, 20) #feature number of movies 20 first hidden layer farklı koyabilirsin\n",
    "        self.fc2 = nn.Linear(20, 10) #20 hiddenden 10 hiddene geliyor 2.hidden layer\n",
    "        self.fc3 = nn.Linear(10, 20) #stacked autoencoders hidden layer 3.hidden layer decoding e geçiyoruz\n",
    "        self.fc4 = nn.Linear(20, nb_movies) #20 den number of movies kadar çıktıya input vector kadar yani\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x)) #fc1 e uyguladık x burada vector or left on fully connection encoded \n",
    "        x = self.activation(self.fc2(x)) #fc2 ye uyguladık\n",
    "        x = self.activation(self.fc3(x)) #fc3 e uyguladık\n",
    "        x = self.fc4(x) #reconstructed output vector için activasyon fonk kullanmıyoruz\n",
    "        return x\n",
    "sae = SAE() #parantez içine bişe tanımlamadık çünkü class içinde tanımladık\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48428c3-ddbd-43b8-86fe-5281b38116f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.7716632528717389\n",
      "epoch: 2, loss: 1.09666233936325\n",
      "epoch: 3, loss: 1.0534029033191739\n",
      "epoch: 4, loss: 1.0383492509876635\n",
      "epoch: 5, loss: 1.0306713919418444\n",
      "epoch: 6, loss: 1.0264345399096706\n",
      "epoch: 7, loss: 1.0238181472001553\n",
      "epoch: 8, loss: 1.022003711900394\n",
      "epoch: 9, loss: 1.0208191949156702\n",
      "epoch: 10, loss: 1.019689263164721\n",
      "epoch: 11, loss: 1.0188434326821711\n",
      "epoch: 12, loss: 1.0183907293428283\n",
      "epoch: 13, loss: 1.0177371669908757\n",
      "epoch: 14, loss: 1.017373927537887\n",
      "epoch: 15, loss: 1.017208351649657\n",
      "epoch: 16, loss: 1.016749642237119\n",
      "epoch: 17, loss: 1.0167955341424215\n",
      "epoch: 18, loss: 1.0163705649547654\n",
      "epoch: 19, loss: 1.016370230842194\n",
      "epoch: 20, loss: 1.0161142656354274\n",
      "epoch: 21, loss: 1.016131707423949\n",
      "epoch: 22, loss: 1.015870928117219\n",
      "epoch: 23, loss: 1.0156605692006393\n",
      "epoch: 24, loss: 1.0155340236739125\n",
      "epoch: 25, loss: 1.0156701097799163\n",
      "epoch: 26, loss: 1.015424710216633\n",
      "epoch: 27, loss: 1.0152304593487083\n",
      "epoch: 28, loss: 1.014950406440314\n",
      "epoch: 29, loss: 1.0129151762543935\n",
      "epoch: 30, loss: 1.0113718820455142\n",
      "epoch: 31, loss: 1.0101685621355225\n",
      "epoch: 32, loss: 1.0071842629775316\n",
      "epoch: 33, loss: 1.0078606758623219\n",
      "epoch: 34, loss: 1.0034730498214046\n",
      "epoch: 35, loss: 1.002469534584799\n",
      "epoch: 36, loss: 0.999663979592799\n",
      "epoch: 37, loss: 0.9983196346241218\n",
      "epoch: 38, loss: 0.9959691079756281\n",
      "epoch: 39, loss: 0.9952853548541347\n",
      "epoch: 40, loss: 0.9923526014044765\n",
      "epoch: 41, loss: 0.9921556499289461\n",
      "epoch: 42, loss: 0.988772116166839\n",
      "epoch: 43, loss: 0.9915940097864342\n",
      "epoch: 44, loss: 0.9863863003511747\n",
      "epoch: 45, loss: 0.9851068447406711\n",
      "epoch: 46, loss: 0.9817262727703218\n",
      "epoch: 47, loss: 0.9808210323759158\n",
      "epoch: 48, loss: 0.9787092395715914\n",
      "epoch: 49, loss: 0.9801404751213288\n",
      "epoch: 50, loss: 0.978999790983676\n",
      "epoch: 51, loss: 0.9779711771953529\n",
      "epoch: 52, loss: 0.9705163716709019\n",
      "epoch: 53, loss: 0.9707327215625812\n",
      "epoch: 54, loss: 0.9702483283494517\n",
      "epoch: 55, loss: 0.9722748070809492\n",
      "epoch: 56, loss: 0.9670402756896207\n",
      "epoch: 57, loss: 0.9704042942327081\n",
      "epoch: 58, loss: 0.9691807385072443\n",
      "epoch: 59, loss: 0.9715736170999647\n",
      "epoch: 60, loss: 0.9650093522925688\n",
      "epoch: 61, loss: 0.9685034246711195\n",
      "epoch: 62, loss: 0.9622837181256819\n",
      "epoch: 63, loss: 0.9676962225938979\n",
      "epoch: 64, loss: 0.9780138940148194\n",
      "epoch: 65, loss: 0.9769251418513505\n",
      "epoch: 66, loss: 0.9719719856724048\n",
      "epoch: 67, loss: 0.9726239963082387\n",
      "epoch: 68, loss: 0.9722796135355731\n",
      "epoch: 69, loss: 0.9671400582759055\n",
      "epoch: 70, loss: 0.9657695438314728\n",
      "epoch: 71, loss: 0.9688735315105637\n",
      "epoch: 72, loss: 0.9627862419068598\n",
      "epoch: 73, loss: 0.9583021330668976\n",
      "epoch: 74, loss: 0.9574414257891892\n",
      "epoch: 75, loss: 0.957949467152259\n",
      "epoch: 76, loss: 0.9617726687050471\n",
      "epoch: 77, loss: 0.9576066470335932\n",
      "epoch: 78, loss: 0.9567156163566669\n",
      "epoch: 79, loss: 0.952865178713925\n",
      "epoch: 80, loss: 0.9515517197442481\n",
      "epoch: 81, loss: 0.9555008551330297\n",
      "epoch: 82, loss: 0.954764792504263\n",
      "epoch: 83, loss: 0.9522774282522593\n",
      "epoch: 84, loss: 0.9499599259933635\n",
      "epoch: 85, loss: 0.9495043811633028\n",
      "epoch: 86, loss: 0.9467760330703141\n",
      "epoch: 87, loss: 0.952587719731097\n",
      "epoch: 88, loss: 0.9573117643094055\n",
      "epoch: 89, loss: 0.9572053628312591\n",
      "epoch: 90, loss: 0.9490974969264235\n",
      "epoch: 91, loss: 0.949741781820212\n",
      "epoch: 92, loss: 0.9523636690271527\n",
      "epoch: 93, loss: 0.9512624781615621\n",
      "epoch: 94, loss: 0.947331361197663\n",
      "epoch: 95, loss: 0.946347420047881\n",
      "epoch: 96, loss: 0.9449252529806552\n",
      "epoch: 97, loss: 0.9429760145909097\n",
      "epoch: 98, loss: 0.9411357823889136\n",
      "epoch: 99, loss: 0.9417189265963459\n",
      "epoch: 100, loss: 0.9412437693741679\n",
      "epoch: 101, loss: 0.9404199385757264\n",
      "epoch: 102, loss: 0.9393211627507357\n",
      "epoch: 103, loss: 0.9397289013890386\n",
      "epoch: 104, loss: 0.9385818006597254\n",
      "epoch: 105, loss: 0.9396066971966571\n",
      "epoch: 106, loss: 0.9393611328588869\n",
      "epoch: 107, loss: 0.9368287073970704\n",
      "epoch: 108, loss: 0.9362780626599874\n",
      "epoch: 109, loss: 0.9365313077784672\n",
      "epoch: 110, loss: 0.9359987256889504\n",
      "epoch: 111, loss: 0.9364612592101071\n",
      "epoch: 112, loss: 0.9355344615839748\n",
      "epoch: 113, loss: 0.9351955433500144\n",
      "epoch: 114, loss: 0.9342704642272506\n",
      "epoch: 115, loss: 0.9328544239137383\n",
      "epoch: 116, loss: 0.9330885585020442\n",
      "epoch: 117, loss: 0.9335890380556271\n",
      "epoch: 118, loss: 0.9326746007514324\n",
      "epoch: 119, loss: 0.9326268597451829\n",
      "epoch: 120, loss: 0.9316024748920364\n",
      "epoch: 121, loss: 0.9319860351042554\n",
      "epoch: 122, loss: 0.9317048445414218\n",
      "epoch: 123, loss: 0.9311786746253398\n",
      "epoch: 124, loss: 0.9312085213335884\n",
      "epoch: 125, loss: 0.9309453879682482\n",
      "epoch: 126, loss: 0.930415681162621\n",
      "epoch: 127, loss: 0.9303112532146168\n",
      "epoch: 128, loss: 0.92987662624074\n",
      "epoch: 129, loss: 0.9292216816667244\n",
      "epoch: 130, loss: 0.9293269871331404\n",
      "epoch: 131, loss: 0.9292910842551321\n",
      "epoch: 132, loss: 0.9291677963193763\n",
      "epoch: 133, loss: 0.9284285805305907\n",
      "epoch: 134, loss: 0.9278833574810237\n",
      "epoch: 135, loss: 0.9276212211245692\n",
      "epoch: 136, loss: 0.9268433657486574\n",
      "epoch: 137, loss: 0.9270349598193744\n",
      "epoch: 138, loss: 0.9261272893401576\n",
      "epoch: 139, loss: 0.927528377547135\n",
      "epoch: 140, loss: 0.9259924444882781\n",
      "epoch: 141, loss: 0.9268131448028725\n",
      "epoch: 142, loss: 0.9258565041460496\n",
      "epoch: 143, loss: 0.9259559840206302\n",
      "epoch: 144, loss: 0.9252350273932965\n",
      "epoch: 145, loss: 0.9254489122516519\n",
      "epoch: 146, loss: 0.9248506246987189\n",
      "epoch: 147, loss: 0.9248872748618907\n",
      "epoch: 148, loss: 0.9243747500574363\n",
      "epoch: 149, loss: 0.9241345144093657\n",
      "epoch: 150, loss: 0.9238369041657987\n",
      "epoch: 151, loss: 0.9236318868417351\n",
      "epoch: 152, loss: 0.9228993387262461\n",
      "epoch: 153, loss: 0.9229885363804105\n",
      "epoch: 154, loss: 0.922444241915597\n",
      "epoch: 155, loss: 0.9223022622021506\n",
      "epoch: 156, loss: 0.9230411594533798\n",
      "epoch: 157, loss: 0.9226524453749065\n",
      "epoch: 158, loss: 0.9222274720334395\n",
      "epoch: 159, loss: 0.9216385694619462\n",
      "epoch: 160, loss: 0.9215922052562036\n",
      "epoch: 161, loss: 0.9212564482217319\n",
      "epoch: 162, loss: 0.9212528421992154\n",
      "epoch: 163, loss: 0.9212158877913527\n",
      "epoch: 164, loss: 0.9208532898763887\n",
      "epoch: 165, loss: 0.9213177721868719\n",
      "epoch: 166, loss: 0.9205124555151102\n",
      "epoch: 167, loss: 0.9198309584080997\n",
      "epoch: 168, loss: 0.9192692293961751\n",
      "epoch: 169, loss: 0.9215317522815812\n",
      "epoch: 170, loss: 0.9195547521647047\n",
      "epoch: 171, loss: 0.9195718476107082\n",
      "epoch: 172, loss: 0.918842799939123\n",
      "epoch: 173, loss: 0.9191244596269195\n",
      "epoch: 174, loss: 0.9182984002513064\n",
      "epoch: 175, loss: 0.918303570115799\n",
      "epoch: 176, loss: 0.9179845667318821\n",
      "epoch: 177, loss: 0.9179739560261984\n",
      "epoch: 178, loss: 0.9173953147223632\n",
      "epoch: 179, loss: 0.9175081051512513\n",
      "epoch: 180, loss: 0.9173106257377018\n",
      "epoch: 181, loss: 0.9171019403922062\n",
      "epoch: 182, loss: 0.9166370591707468\n",
      "epoch: 183, loss: 0.9165896560351481\n",
      "epoch: 184, loss: 0.9179145158972812\n",
      "epoch: 185, loss: 0.9164101589346152\n",
      "epoch: 186, loss: 0.915980538530439\n",
      "epoch: 187, loss: 0.9164358665697325\n",
      "epoch: 188, loss: 0.916228600337268\n",
      "epoch: 189, loss: 0.9159210240318482\n",
      "epoch: 190, loss: 0.9155170369360495\n",
      "epoch: 191, loss: 0.9158837801595203\n",
      "epoch: 192, loss: 0.9150947267654054\n",
      "epoch: 193, loss: 0.9156240929506425\n",
      "epoch: 194, loss: 0.9153858318564055\n",
      "epoch: 195, loss: 0.9148496661911398\n",
      "epoch: 196, loss: 0.9144311003156964\n",
      "epoch: 197, loss: 0.9147925139898518\n",
      "epoch: 198, loss: 0.9142889713530397\n",
      "epoch: 199, loss: 0.9145023489115831\n",
      "epoch: 200, loss: 0.9135754001991595\n"
     ]
    }
   ],
   "source": [
    "# Eğitim\n",
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = training_set[id_user].unsqueeze(0)  # Variable kaldırıldı\n",
    "        target = input.clone()\n",
    "        if torch.sum(target > 0) > 0:  # target.data yerine doğrudan target\n",
    "            output = sae(input)\n",
    "            target.requires_grad_(False)  # require_grad yerine requires_grad_\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies / float(torch.sum(target > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.item() * mean_corrector)  # loss.data[0] yerine loss.item()\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print(f'epoch: {epoch}, loss: {train_loss/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6eb1e71-01a9-4c29-bf33-cabb7709c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9495550151221323\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = training_set[id_user].unsqueeze(0)  # Variable kaldırıldı\n",
    "    target = test_set[id_user].unsqueeze(0)\n",
    "    if torch.sum(target > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.requires_grad_(False)\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies / float(torch.sum(target > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item() * mean_corrector)  # loss.data yerine loss.item()\n",
    "        s += 1.\n",
    "print(f'test loss: {test_loss/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505c85f-d60a-4be0-9815-560f0cfabdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
