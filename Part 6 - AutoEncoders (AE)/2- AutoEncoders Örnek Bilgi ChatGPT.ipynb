{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94753ebe-0cd1-4929-b74b-b29795c8afa9",
   "metadata": {},
   "source": [
    "Süper—hem kodu **adım adım** açıklayayım, hem de **hata veren yerleri** modern PyTorch ile **düzelten** küçük bir örnek kod bırakayım. Önce senin kodunun mantığı:\n",
    "\n",
    "---\n",
    "\n",
    "## Neden PyTorch? Neden `class` (nn.Module)?\n",
    "\n",
    "* **PyTorch** otomatik türev (**autograd**) ve GPU hızlandırma verir; tensor operasyonlarıyla ileri/geri yayılımı kendisi çıkarır.\n",
    "* Bir ağı **`nn.Module` sınıfı** olarak yazınca:\n",
    "\n",
    "  * Parametreler otomatik **kayıt** edilir (optimizer kolay).\n",
    "  * **`forward`** ile akışı tanımlarsın; geri yayılımı PyTorch hesaplar.\n",
    "  * **`.to(device)`** ile komple modeli GPU/CPU’ya taşımak basit olur.\n",
    "\n",
    "---\n",
    "\n",
    "## Kodun aşama aşama açıklaması\n",
    "\n",
    "### 1) Veri hazırlığı\n",
    "\n",
    "```python\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t').values\n",
    "test_set     = pd.read_csv('ml-100k/u1.test',  delimiter = '\\t').values\n",
    "nb_users  = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "```\n",
    "\n",
    "* **u1.base/u1.test** satırları: `(user_id, movie_id, rating, timestamp)`.\n",
    "* Kullanıcı ve film sayısını buluyoruz.\n",
    "\n",
    "```python\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies  = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "```\n",
    "\n",
    "* Her kullanıcı için **yoğun (dense)** bir **kullanıcı×film** vektörü oluşturuyor (oylanmamış filmler `0` kalıyor).\n",
    "\n",
    "```python\n",
    "training_set = torch.FloatTensor(convert(training_set))\n",
    "test_set     = torch.FloatTensor(convert(test_set))\n",
    "```\n",
    "\n",
    "### 2) Stacked Autoencoder (SAE) mimarisi\n",
    "\n",
    "```python\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)     # bottleneck (latent 10)\n",
    "        self.fc3 = nn.Linear(10, 20)     # decoder\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)                  # çıkışta aktivasyon yok (lineer)\n",
    "        return x\n",
    "```\n",
    "\n",
    "* **Encoder:** nb\\_movies → 20 → 10\n",
    "* **Decoder:** 10 → 20 → nb\\_movies\n",
    "* Bu bir **undercomplete AE** (sıkıştırma: 10 boyut).\n",
    "* Aktivasyonlar `Sigmoid`. (Çıkış katmanında aktivasyon yok.)\n",
    "\n",
    "> Not: Çıktı **0–5** aralığındaki ratingleri yeniden kuracaksa, iki seçenekten biri daha doğal olur:\n",
    ">\n",
    "> * Ratingleri **\\[0,1]** ölçeğine çekip **çıktıya `Sigmoid`** koymak, **veya**\n",
    "> * Ratingleri **\\[0,5]** bırakıp **çıktıyı lineer** tutmak (şu anki gibi).\n",
    ">   Eğitimin stabil olması için genelde **ölçekleme önerilir** (aşağıda vereceğim örnek kodda ölçekli versiyonu göstereceğim).\n",
    "\n",
    "### 3) Eğitim döngüsü (kullanıcı bazlı, maskeleme)\n",
    "\n",
    "* Girdi `input = training_set[id_user].unsqueeze(0)` (tek kullanıcı = tek batch).\n",
    "\n",
    "* `target = input.clone()` (rekonstrüksiyon hedefi input’un kendisi).\n",
    "\n",
    "* **Maskeleme:** Kullanıcı hangi filmlere oy verdiyse (target > 0) sadece **onlarda** hatayı hesaba katmak istiyoruz. Bu yüzden:\n",
    "\n",
    "  ```python\n",
    "  output = sae(input)\n",
    "  output[target == 0] = 0  # oylanmamış (0) yerlerde hatayı sıfırla\n",
    "  loss = criterion(output, target)\n",
    "  ```\n",
    "\n",
    "* Ortalama hata adil olsun diye, **oylanan film sayısına** göre düzeltiyor:\n",
    "\n",
    "  ```python\n",
    "  mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
    "  ```\n",
    "\n",
    "  Sonra **RMSE** benzeri bir rapor için `np.sqrt(loss * mean_corrector)` ekleniyor.\n",
    "\n",
    "* **Optimizer:** `RMSprop(lr=0.01, weight_decay=0.5)` (weight\\_decay=0.5 modern standartlara göre epey büyük; tipik değerler 1e-5–1e-3 arasıdır.)\n",
    "\n",
    "---\n",
    "\n",
    "## Hatanın sebebi ve çözümü\n",
    "\n",
    "Hata:\n",
    "\n",
    "```\n",
    "IndexError: invalid index of a 0-dim tensor.\n",
    "train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "```\n",
    "\n",
    "* Yeni PyTorch sürümlerinde `loss.data` **0-boyutlu tensordur**; `[0]` ile indekslenmez.\n",
    "* **Çözüm:** `.item()` kullan:\n",
    "\n",
    "  ```python\n",
    "  train_loss += np.sqrt(loss.item() * mean_corrector)\n",
    "  ```\n",
    "\n",
    "Ayrıca **modern PyTorch kalıbı**:\n",
    "\n",
    "* `Variable` artık kullanılmıyor (Tensor yeterli).\n",
    "* Her iterasyonda **`optimizer.zero_grad()` → `loss.backward()` → `optimizer.step()`** sırası.\n",
    "* `target.require_grad = False` (typo) yerine `target.requires_grad_(False)` veya hiç gerek yok.\n",
    "\n",
    "---\n",
    "\n",
    "## Daha temiz ve modern örnek (maskeli MSE + ölçekleme)\n",
    "\n",
    "Aşağıdaki örnek:\n",
    "\n",
    "* Ratingleri **\\[0,1]** aralığına ölçekler (`/5.0`),\n",
    "* **Maskeli MSE** ile sadece **oylanan** yerlerde loss hesaplar,\n",
    "* `optimizer.zero_grad()` ve `.item()` kullanır,\n",
    "* Testte **maskeli RMSE** raporlar.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ---------- Veri yükleme ve dönüştürme ----------\n",
    "def load_ml100k_matrix(base_path=\"ml-100k\"):\n",
    "    tr = pd.read_csv(f\"{base_path}/u1.base\", delimiter=\"\\t\", header=None, names=[\"u\",\"i\",\"r\",\"t\"]).values\n",
    "    te = pd.read_csv(f\"{base_path}/u1.test\", delimiter=\"\\t\", header=None, names=[\"u\",\"i\",\"r\",\"t\"]).values\n",
    "    nb_users  = int(max(tr[:,0].max(), te[:,0].max()))\n",
    "    nb_movies = int(max(tr[:,1].max(), te[:,1].max()))\n",
    "    def to_matrix(data):\n",
    "        X = np.zeros((nb_users, nb_movies), dtype=np.float32)\n",
    "        for u in range(1, nb_users+1):\n",
    "            movies  = data[:,1][data[:,0] == u]\n",
    "            ratings = data[:,2][data[:,0] == u]\n",
    "            X[u-1, movies-1] = ratings\n",
    "        return X\n",
    "    return to_matrix(tr), to_matrix(te)\n",
    "\n",
    "Xtr, Xte = load_ml100k_matrix()\n",
    "\n",
    "# Ölçekleme [0,1]; mask (oylananlar)\n",
    "def binarize_or_scale(X):\n",
    "    mask = (X > 0).astype(np.float32)     # bilinen yerler\n",
    "    Xsc  = (X / 5.0).astype(np.float32)   # 0..5 -> 0..1\n",
    "    return Xsc, mask\n",
    "\n",
    "Vtr, Mtr = binarize_or_scale(Xtr)\n",
    "Vte, Mte = binarize_or_scale(Xte)\n",
    "\n",
    "Vtr = torch.from_numpy(Vtr)   # (U, I)\n",
    "Mtr = torch.from_numpy(Mtr)\n",
    "Vte = torch.from_numpy(Vte)\n",
    "Mte = torch.from_numpy(Mte)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Vtr, Mtr, Vte, Mte = Vtr.to(device), Mtr.to(device), Vte.to(device), Mte.to(device)\n",
    "\n",
    "# ---------- Model ----------\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, n_items):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_items, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)     # bottleneck\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc4 = nn.Linear(128, n_items)\n",
    "        self.act = nn.ReLU()\n",
    "        self.out = nn.Sigmoid()           # 0..1 ölçeği için\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.act(self.fc3(x))\n",
    "        x = self.out(self.fc4(x))         # 0..1 tahmin\n",
    "        return x\n",
    "\n",
    "model = SAE(n_items=Vtr.size(1)).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Maskeli MSE: sadece bilinenlerde hata\n",
    "def masked_mse(pred, target, mask, eps=1e-8):\n",
    "    se = ((pred - target) ** 2) * mask\n",
    "    return se.sum() / (mask.sum() + eps)\n",
    "\n",
    "# ---------- Eğitim ----------\n",
    "epochs = 50\n",
    "model.train()\n",
    "for ep in range(1, epochs+1):\n",
    "    opt.zero_grad()\n",
    "    # (Bu örnekte bütün kullanıcıları tek batch'te veriyoruz; istersen mini-batch yapabilirsin)\n",
    "    out = model(Vtr)\n",
    "    loss = masked_mse(out, Vtr, Mtr)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if ep % 5 == 0 or ep == 1:\n",
    "        # RMSE raporu (bilinenlerde)\n",
    "        rmse = torch.sqrt(masked_mse(out, Vtr, Mtr)).item()\n",
    "        print(f\"Epoch {ep:02d} | train RMSE: {rmse:.4f}\")\n",
    "\n",
    "# ---------- Test ----------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_te = model(Vte)\n",
    "    test_rmse = torch.sqrt(masked_mse(pred_te, Vte, Mte)).item()\n",
    "print(f\"Test RMSE (known entries): {test_rmse:.4f}\")\n",
    "```\n",
    "\n",
    "### Neler değişti / neden daha iyi?\n",
    "\n",
    "* **`Variable` yok**, modern PyTorch tensorları yeterli.\n",
    "* **`.item()`** kullanıyoruz (0-dim tensor → Python float).\n",
    "* **`optimizer.zero_grad()`** her iterasyonda çağrılıyor.\n",
    "* **Maske** ile yalnız **oylanan** yerlerde loss:\n",
    "\n",
    "  * Senin yaklaşımındaki `output[target==0]=0` fikren aynı sonucu hedefliyor ama **loss’u açıkça maskeyle** yazmak daha temiz, hatasız.\n",
    "* **Çıkış aktivasyonu Sigmoid** çünkü ratingleri **0..1** ölçeğine aldık.\n",
    "  (Dilersen ratingleri olduğu gibi tutup **output’u lineer** bırakabilirsin; o zaman kayıplar/öğrenme oranını yeniden ayarlamak gerekir.)\n",
    "\n",
    "---\n",
    "\n",
    "## Kısa özet (akılda kalsın)\n",
    "\n",
    "* **AE**: girdi = çıktı (rekonstrüksiyon), **bottleneck** → temsil öğrenme.\n",
    "* **Maskeleme** şart: oylanmamış öğelerde kayıp hesaplanmaz.\n",
    "* **Hatan:** `.data[0]` yerine **`.item()`** kullan.\n",
    "* **Modern kalıp:** `zero_grad()` → `backward()` → `step()`; `Variable` yok.\n",
    "* **Ölçekleme** ve/veya **uygun çıkış aktivasyonu** (Sigmoid/Tanh/Linear) seçimi eğitimi çok rahatlatır.\n",
    "\n",
    "İstersen bunu **mini-batch** (DataLoader) haline çevireyim veya **Sparse AE / Denoising AE** varyantını aynı MovieLens üzerinde de gösterebilirim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45262d-a4e5-4554-9458-96f044920616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
