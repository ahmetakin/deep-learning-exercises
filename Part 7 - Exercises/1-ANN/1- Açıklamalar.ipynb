{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146d50cb-e8a9-46ba-97e0-6757fa84c58b",
   "metadata": {},
   "source": [
    "SÃ¼per bir kurgu yapmÄ±ÅŸsÄ±n. AÅŸaÄŸÄ±da kodundaki her adÄ±mÄ±, â€œneden bÃ¶yle?â€ sorularÄ±nÄ± tek tek aÃ§Ä±klÄ±yorum; ardÄ±ndan verdiÄŸin Ã¶rnek satÄ±rlar ile **tahmin alma**, **modeli kaydetme/yÃ¼kleme** ve **yeni veriyle devam eÄŸitimi (fine-tune)** iÃ§in tam kod veriyorum.\n",
    "\n",
    "---\n",
    "\n",
    "# AdÄ±m AdÄ±m AÃ§Ä±klamalar\n",
    "\n",
    "## 1) `y` iÃ§in `.values` kullandÄ±k, `X` iÃ§in kullanmadÄ±k â€” neden?\n",
    "\n",
    "* `y = dataset[\"Injury_Next_Season\"].values` ile **hedefi** `numpy` dizisine Ã§eviriyorsun. Sklearn/Keras ikisiyle de uyumlu.\n",
    "* `X`â€™i **DataFrame** olarak tutmak Ã¶nemli; Ã§Ã¼nkÃ¼ **`ColumnTransformer` kolon adlarÄ±na gÃ¶re** (isimle) iÅŸlem yapÄ±yor. EÄŸer baÅŸta `X.values` yapsaydÄ±n, kolon adlarÄ± kaybolur, seÃ§tiÄŸin sayÄ±sal/kategorik sÃ¼tun listeleri boÅŸa dÃ¼ÅŸer.\n",
    "* Ã–zet: **y = array**, **X = DataFrame** kalmalÄ±.\n",
    "\n",
    "## 2) Neden iki aÅŸamalÄ± bÃ¶lme: `X_train, X_temp, ...` ve sonra `X_valid, X_test, ...`?\n",
    "\n",
    "* EÄŸitim/DoÄŸrulama/Test olarak **3â€™e bÃ¶lmek** istiyoruz.\n",
    "* Sklearnâ€™de tek fonksiyonla 3â€™lÃ¼ split yok, bu yÃ¼zden:\n",
    "\n",
    "  1. Ã–nce Train vs Temp (Train %70 â€“ Temp %30)\n",
    "  2. Sonra Tempâ€™i Valid vs Test (%15 â€“ %15) diye ikiye bÃ¶lÃ¼yoruz.\n",
    "* `stratify=y` sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± her bÃ¶lmede korur (denge bozulmaz).\n",
    "\n",
    "## 3) Neden `fit_transform(train)` ama sadece `transform(valid/test)`?\n",
    "\n",
    "* **Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)** olmamasÄ± iÃ§in **scaler/ohe/imputer** gibi istatistikleri **sadece train** Ã¼zerinde Ã¶ÄŸrenmeliyiz.\n",
    "* `preprocess.fit_transform(X_train)`: imputer medyanlarÄ±, OHE kategori listesi, scaler ortalama-std **trainâ€™de fit edilir** ve trainâ€™e uygulanÄ±r.\n",
    "* `preprocess.transform(X_valid/X_test)`: valid/test Ã¼zerinde **fit edilmez**, sadece **aynÄ± dÃ¶nÃ¼ÅŸÃ¼m** uygulanÄ±r.\n",
    "* `feature_dim = X_train_p.shape[1]`: OHEâ€™den sonra **Ã¶zellik sayÄ±sÄ± artabilir**; bu nedenle gerÃ§ek giriÅŸ boyutunu **pipeline Ã§Ä±ktÄ±sÄ±ndan** Ã¶lÃ§mek gerekir. ANN giriÅŸ katmanÄ±nÄ± buna gÃ¶re kuruyoruz.\n",
    "\n",
    "## 4) `class_weight` neden hesaplandÄ±?\n",
    "\n",
    "* SÄ±nÄ±flar **tam dengeli** bile olsa, kÃ¼Ã§Ã¼k veri setlerinde veya loss yÃ¼zÃ¼nden **minÃ¶r dengesizlik etkilerini** telafi etmek iyi sonuÃ§ verir.\n",
    "* `compute_class_weight(..., y=y_train)` sadece **train** daÄŸÄ±lÄ±mÄ±na gÃ¶re **\\[sÄ±nÄ±f -> aÄŸÄ±rlÄ±k]** hesaplar; `model.fit(..., class_weight=...)` ile loss tarafÄ±nda pozitif/negatif hatalarÄ± eÅŸitler.\n",
    "* Veri dengeli ise aÄŸÄ±rlÄ±klar genelde 1â€™e yakÄ±n Ã§Ä±kar; dengesiz olsa bile **kÃ¼Ã§Ã¼k eforla bÃ¼yÃ¼k fark** yaratabilir.\n",
    "\n",
    "## 5) `build_model` ve â€œSequential yapmadÄ±k mÄ±?â€ sorusu\n",
    "\n",
    "* AslÄ±nda **`keras.Sequential`** kullandÄ±n. Yani â€œSequential yapmadÄ±kâ€ deÄŸil; **tam olarak Sequential yaptÄ±n** ğŸ™‚\n",
    "* Alternatif olarak **Functional API** de kullanÄ±labilirdi (Ã§oklu girdi, yan kol, embedding vs. gerektiÄŸinde).\n",
    "* Buradaki katmanlar: `Dense(64, relu) -> Dropout -> Dense(32, relu) -> Dropout/2 -> Dense(1, sigmoid)`.\n",
    "\n",
    "  * **ReLU**: derin aÄŸlarda iyi Ã§alÄ±ÅŸÄ±r.\n",
    "  * **Dropout**: aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfit) azaltÄ±r.\n",
    "  * **Sigmoid**: ikili sÄ±nÄ±flandÄ±rma Ã§Ä±kÄ±ÅŸÄ± (0â€“1 olasÄ±lÄ±k).\n",
    "\n",
    "## 6) `EarlyStopping` ve `ReduceLROnPlateau` (plateau)\n",
    "\n",
    "* **EarlyStopping**: Val setindeki bir metriÄŸi izler (sen **`val_auc`** seÃ§miÅŸsin). Bir sÃ¼re **iyileÅŸme olmazsa** eÄŸitimi durdurur ve **en iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kler** (`restore_best_weights=True`). Overfitâ€™i Ã¶nler, zamanÄ± kurtarÄ±r.\n",
    "* **ReduceLROnPlateau**: Val loss iyileÅŸmeyi bÄ±rakÄ±nca **Ã¶ÄŸrenme oranÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r** (`factor=0.5`). BÃ¼yÃ¼k LR ile â€œtakÄ±lÄ±pâ€ kalmayÄ± Ã¶nler, daha kÃ¼Ã§Ã¼k adÄ±mlarla iyileÅŸme ÅŸansÄ± verir.\n",
    "\n",
    "## 7) `history` nedir?\n",
    "\n",
    "* `model.fit(...)` **her epochâ€™taki loss/metric** deÄŸerlerini bir sÃ¶zlÃ¼kte toplar (`history.history`).\n",
    "* Bunu `pd.DataFrame`â€™e Ã§evirip grafiklemek, **overfit/underfit** tanÄ±sÄ±nÄ± kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "## 8) EÄŸitim grafikleri kodu ne yapÄ±yor?\n",
    "\n",
    "* `hist = pd.DataFrame(history.history)` ile train/val **loss** ve **AUC** eÄŸrilerini Ã§iziyorsun.\n",
    "* Loss dÃ¼ÅŸerken val\\_loss yÃ¼kselirse overfit; her ikisi de dÃ¼ÅŸÃ¼yorsa iyi; val dÃ¼zleÅŸirse LR azaltma/erken durdurma devrede.\n",
    "\n",
    "## 9) Test deÄŸerlendirme (0.5 eÅŸik)\n",
    "\n",
    "* `y_proba = model.predict(X_test_p).ravel()` â†’ **olasÄ±lÄ±klar** (0â€“1).\n",
    "* `y_pred = (y_proba >= 0.5).astype(int)` â†’ **etiket** (0/1). 0.5 **varsayÄ±lan** bir eÅŸiktir; problemi/Ã¶ncelikleri gÃ¶re ayarlanabilir.\n",
    "* Metrikler:\n",
    "\n",
    "  * **AUC** (ROC AUC): eÅŸikten baÄŸÄ±msÄ±z ayrÄ±m gÃ¼cÃ¼.\n",
    "  * **Accuracy/Precision/Recall/F1**: eÅŸik **seÃ§imine baÄŸlÄ±** sonuÃ§lar.\n",
    "* `classification_report` ve `confusion_matrix` sÄ±nÄ±f bazlÄ± performansÄ± gÃ¶sterir.\n",
    "\n",
    "## 10) ROC ve PR eÄŸrileri\n",
    "\n",
    "* **ROC**: FPRâ€“TPR eÄŸrisi, **AUC** ile Ã¶zetlenir. SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± dengeliyken daha aÃ§Ä±klayÄ±cÄ±.\n",
    "* **PR**: Precisionâ€“Recall eÄŸrisi, **AP (Average Precision)** ile Ã¶zetlenir. Pozitif sÄ±nÄ±f **nadir** olduÄŸunda daha bilgilendiricidir.\n",
    "\n",
    "## 11) EÅŸik (threshold) optimizasyonu\n",
    "\n",
    "* 0.1â€“0.9 arasÄ±nda eÅŸikleri tarayÄ±p **F1â€™i maksimize** eden eÅŸiÄŸi arÄ±yorsun.\n",
    "* F1, precision/recall dengesini saÄŸlar. Maliyet fonksiyonuna gÃ¶re **baÅŸka bir metrik** de seÃ§ilebilirdi (Ã¶rneÄŸin recall Ã¶ncelikli ise recall\\@thresholdâ€™u maksimize etmek).\n",
    "\n",
    "---\n",
    "\n",
    "# Uygulama: Ã–rnek Verilerle Tahmin, Model Kaydet/YÃ¼kle ve Devam EÄŸitimi\n",
    "\n",
    "AÅŸaÄŸÄ±daki bloklar, **senin kurduÄŸun pipeline ile birebir uyumlu**.\n",
    "Not: VerdiÄŸin â€œ5 satÄ±râ€ Ã¶rnekte **4 satÄ±r** var; o ÅŸekilde kullandÄ±m.\n",
    "\n",
    "## A) Ã–rnek veriden tahmin alma\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Ã–rnek veriyi DataFrame'e Ã§evir\n",
    "sample_csv = \"\"\"Age,Height_cm,Weight_kg,Position,Training_Hours_Per_Week,Matches_Played_Past_Season,Previous_Injury_Count,Knee_Strength_Score,Hamstring_Flexibility,Reaction_Time_ms,Balance_Test_Score,Sprint_Speed_10m_s,Agility_Score,Sleep_Hours_Per_Night,Stress_Level_Score,Nutrition_Quality_Score,Warmup_Routine_Adherence,Injury_Next_Season,BMI\n",
    "22,173,64,Midfielder,11.575308026077138,36,1,77.46027901003853,79.11573817783952,284.48785262294393,91.21247628562678,5.874629899095096,77.59970508640522,8.238293030872281,46.61641520851219,81.47220606471353,1,0,21.383941996057334\n",
    "18,170,67,Midfielder,12.275869450190173,37,2,72.6344422606009,82.54168794778663,250.57924940551655,87.29407824138767,5.796269352614358,94.4189869374685,8.983737193266625,49.36803674229354,81.05667689014356,1,0,23.18339100346021\n",
    "22,186,75,Forward,12.254895659208355,12,2,77.0644897841478,75.94363053556577,269.11991825792603,83.4406884700333,5.731208756193826,70.17917629629453,7.229192653844745,43.13280804133722,64.87745688032112,0,1,21.678806798473808\n",
    "20,172,62,Defender,9.00667756614741,11,1,82.81023161351551,73.8783244426281,226.3764118453216,87.59189360708152,6.220212239929888,83.47382412454475,7.681028808856083,51.528529395795616,89.82474393936592,1,0,20.9572742022715\n",
    "\"\"\"\n",
    "from io import StringIO\n",
    "sample_df = pd.read_csv(StringIO(sample_csv))\n",
    "\n",
    "# 2) Hedefi ayÄ±r (varsa). Tahmin alÄ±rken hedefe ihtiyacÄ±mÄ±z yok.\n",
    "X_new = sample_df.drop(columns=[\"Injury_Next_Season\"])\n",
    "\n",
    "# 3) EÄŸitimde fit ettiÄŸin PREPROCESSOR'u kullanarak dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "# preprocess ve model zaten bellekteyse direkt kullan:\n",
    "X_new_p = preprocess.transform(X_new)\n",
    "\n",
    "# 4) OlasÄ±lÄ±k ve etiket tahminleri\n",
    "y_new_proba = model.predict(X_new_p).ravel()\n",
    "y_new_pred  = (y_new_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"OlasÄ±lÄ±klar:\", y_new_proba.round(3))\n",
    "print(\"Tahminler  :\", y_new_pred.tolist())\n",
    "```\n",
    "\n",
    "> Not: Pipelineâ€™daki `OneHotEncoder(handle_unknown=\"ignore\")` sayesinde **yeni bir Position** gelse bile hata almazsÄ±n (sÄ±fÄ±r vektÃ¶rÃ¼ verir).\n",
    "\n",
    "---\n",
    "\n",
    "## B) Modeli ve Ã¶n-iÅŸlemeyi kaydetmek / yÃ¼klemek\n",
    "\n",
    "### Kaydetme\n",
    "\n",
    "```python\n",
    "# 1) Keras modeli kaydet\n",
    "model.save(\"injury_ann.keras\")  # veya 'injury_ann.h5'\n",
    "\n",
    "# 2) Sklearn preprocessÃ¶rÃ¼ kaydet\n",
    "import joblib\n",
    "joblib.dump(preprocess, \"preprocess.joblib\")\n",
    "\n",
    "# (Ä°steÄŸe baÄŸlÄ±) EÅŸik ve versiyon notlarÄ±:\n",
    "best_threshold_to_save = 0.5  # istersen hesapladÄ±ÄŸÄ±n t_star'Ä± kaydet\n",
    "meta = {\"threshold\": best_threshold_to_save, \"version\": \"v1.0\"}\n",
    "joblib.dump(meta, \"meta.joblib\")\n",
    "```\n",
    "\n",
    "### YÃ¼kleme ve kullanma\n",
    "\n",
    "```python\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1) YÃ¼kle\n",
    "loaded_model = keras.models.load_model(\"injury_ann.keras\")\n",
    "loaded_preprocess = joblib.load(\"preprocess.joblib\")\n",
    "meta = joblib.load(\"meta.joblib\")  # threshold vb.\n",
    "\n",
    "# 2) Yeni veriyi oku ve dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "X_infer = X_new  # Ã¶rnek olarak yukarÄ±daki sample'dan\n",
    "X_infer_p = loaded_preprocess.transform(X_infer)\n",
    "\n",
    "# 3) Tahmin\n",
    "proba = loaded_model.predict(X_infer_p).ravel()\n",
    "pred  = (proba >= meta[\"threshold\"]).astype(int)\n",
    "print(\"proba:\", proba)\n",
    "print(\"pred :\", pred)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## C) Yeni veriyle modeli â€œbeslemekâ€ (devam eÄŸitimi)\n",
    "\n",
    "Burada iki ayrÄ± katman var:\n",
    "\n",
    "1. **Ã–n-iÅŸleme** (imputer, scaler, OHE):\n",
    "\n",
    "* **SeÃ§enek-1 (Stabil Ã¼retim)**: **Eski preprocessÃ¶rÃ¼ dondur** ve **yeni veriyi de aynÄ± dÃ¶nÃ¼ÅŸÃ¼mle** geÃ§ir.\n",
    "\n",
    "  * Avantaj: Ãœretimde istikrar, kolay yÃ¶netim.\n",
    "  * Dezavantaj: Yeni **kategoriler** (yeni `Position`) OHEâ€™de **Ã¶ÄŸrenilmez**, â€œignoreâ€ edilir (vektÃ¶rleri sÄ±fÄ±r kalÄ±r).\n",
    "* **SeÃ§enek-2 (GÃ¼ncelleme)**: **Eski veri + yeni veriyi birleÅŸtirip** preprocessÃ¶rÃ¼ **yeniden fit** et.\n",
    "\n",
    "  * Avantaj: Yeni kategoriler/features daÄŸÄ±lÄ±mlarÄ± tanÄ±nÄ±r.\n",
    "  * Dezavantaj: Eski modelle birebir aynÄ± giriÅŸ boyutu olmayabilir (OHE boyutu deÄŸiÅŸebilir); **modeli de yeniden eÄŸitmek** gerekir.\n",
    "\n",
    "2. **Model**:\n",
    "\n",
    "* **Devam eÄŸitimi (fine-tune)**: AynÄ± mimari ile, **yÃ¼klediÄŸin modeli** yeni verinin **dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ** (preprocess edilmiÅŸ) versiyonu Ã¼stÃ¼nde **kÃ¼Ã§Ã¼k LR** ile eÄŸitmeye devam edebilirsin.\n",
    "\n",
    "### Devam eÄŸitimi â€“ Kod\n",
    "\n",
    "```python\n",
    "# VarsayÄ±m: \"loaded_model\" ve \"loaded_preprocess\" yÃ¼klendi.\n",
    "# Yeni veriniz (CSV) var:\n",
    "new_df = pd.read_csv(\"football_injury_new.csv\")\n",
    "\n",
    "# Hedefi ayÄ±r\n",
    "y_new = new_df[\"Injury_Next_Season\"].values\n",
    "X_new = new_df.drop(columns=[\"Injury_Next_Season\"])\n",
    "\n",
    "# SeÃ§enek-1: preprocessÃ¶rÃ¼ dondurup kullan\n",
    "X_new_p = loaded_preprocess.transform(X_new)\n",
    "\n",
    "# Devam eÄŸitimi iÃ§in dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±\n",
    "from tensorflow.keras import optimizers\n",
    "loaded_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=5e-4),  # baÅŸlangÄ±ca gÃ¶re daha kÃ¼Ã§Ã¼k LR\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\"),\n",
    "             keras.metrics.Precision(name=\"precision\"),\n",
    "             keras.metrics.Recall(name=\"recall\")]\n",
    ")\n",
    "\n",
    "# class_weight istersen yine hesapla (yeni eÄŸitim setine gÃ¶re)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_new)\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_new)\n",
    "cw_dict = {int(c): w for c, w in zip(classes, cw)}\n",
    "\n",
    "early2 = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", mode=\"max\", patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# kÃ¼Ã§Ã¼k bir validasyon ayÄ±r\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xn_tr, Xn_va, yn_tr, yn_va = train_test_split(X_new_p, y_new, test_size=0.2, stratify=y_new, random_state=1)\n",
    "\n",
    "hist2 = loaded_model.fit(\n",
    "    Xn_tr, yn_tr,\n",
    "    validation_data=(Xn_va, yn_va),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    class_weight=cw_dict,\n",
    "    callbacks=[early2],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# GÃ¼ncellenmiÅŸ modeli tekrar kaydet\n",
    "loaded_model.save(\"injury_ann_finetuned.keras\")\n",
    "```\n",
    "\n",
    "> **Ã–nemli notlar**\n",
    ">\n",
    "> * **SeÃ§enek-2** (preprocessÃ¶rÃ¼ yeniden fit etmek) yapacaksan, **X\\_train/X\\_valid/X\\_test** ile **X\\_new**â€™i birleÅŸtir, **yeni bir `preprocess.fit`** yap, **aÄŸ giriÅŸ boyutu** (OHE nedeniyle) deÄŸiÅŸebileceÄŸi iÃ§in **modeli sÄ±fÄ±rdan** (veya ilk layerâ€™i adapte ederek) yeniden eÄŸit.\n",
    "> * Ãœretim hattÄ±nda genelde **SeÃ§enek-1** tercih edilir; belirli periyotlarda â€œversiyon yÃ¼kseltmesiâ€ ile SeÃ§enek-2 planlÄ± yapÄ±lÄ±r.\n",
    "\n",
    "---\n",
    "\n",
    "## D) (Ä°steÄŸe baÄŸlÄ±) En iyi eÅŸiÄŸi kaydedip yÃ¼klemek\n",
    "\n",
    "Tahmin sonrasÄ± **karar eÅŸiÄŸini** (Ã¶r. `t_star`) kaydedip Ã¼retimde kullan:\n",
    "\n",
    "```python\n",
    "# HesaplamÄ±ÅŸtÄ±n:\n",
    "# t_star, s_star = best_threshold(y_test, y_proba, metric=\"f1\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump({\"threshold\": float(t_star)}, \"decision_threshold.joblib\")\n",
    "\n",
    "# YÃ¼kleyip kullanma:\n",
    "th = joblib.load(\"decision_threshold.joblib\")[\"threshold\"]\n",
    "pred = (proba >= th).astype(int)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# KÄ±sa Ã–zet (sorularÄ±nÄ±n Ã§ekirdeÄŸi)\n",
    "\n",
    "* **`y.values`**: yâ€™yi array yapmak doÄŸal; **Xâ€™i DataFrame** tutmamÄ±z **kolon isimleriyle** Ã§alÄ±ÅŸan `ColumnTransformer` iÃ§in ÅŸart.\n",
    "* **3â€™lÃ¼ split**: Train/Valid/Test ayrÄ±mÄ± iÃ§in iki aÅŸamalÄ± bÃ¶lme.\n",
    "* **`fit_transform(train)` / `transform(valid/test)`**: sÄ±zÄ±ntÄ±yÄ± Ã¶nlemek ve gerÃ§ekÃ§i deÄŸerlendirme iÃ§in.\n",
    "* **`feature_dim`**: OHE sonrasÄ± gerÃ§ek giriÅŸ boyutunu almak iÃ§in.\n",
    "* **`class_weight`**: Dengeyi korumak, kÃ¼Ã§Ã¼k dengesizlikleri telafi etmek.\n",
    "* **Sequential**: Zaten Sequential kullandÄ±n; Functional API, Ã§oklu giriÅŸ/karmaÅŸÄ±k mimaride gerekli olur.\n",
    "* **EarlyStopping & ReduceLROnPlateau**: Overfitâ€™i ve gereksiz epochâ€™larÄ± engeller, LRâ€™Ä± dinamik kÃ¼Ã§Ã¼ltÃ¼r.\n",
    "* **`history`**: EÄŸitim metriklerinin zaman iÃ§i kaydÄ±; grafikle teÅŸhis yaparsÄ±n.\n",
    "* **ROC/PR & threshold**: EÅŸik-agnostik (AUC/AP) analiz + uygulama eÅŸiÄŸini probleme gÃ¶re optimize etme.\n",
    "\n",
    "TakÄ±ldÄ±ÄŸÄ±n baÅŸka nokta varsa veya **embeddingâ€™li pozisyon temsili** versiyonunu da (ANN iÃ§inde) gÃ¶rmek istersen, onu da tam kodla veririm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b230e-9de1-489f-8db8-23ab17cc0e26",
   "metadata": {},
   "source": [
    "**â€œEÅŸik deÄŸeri (threshold)â€**:\n",
    "Modelin Ã§Ä±ktÄ±sÄ± **olasÄ±lÄ±ktÄ±r** (Ã¶r. `P(injury=1)` = 0.73). Bu olasÄ±lÄ±ÄŸÄ± **etikete** (0/1) Ã§evirmek iÃ§in bir **karar eÅŸiÄŸi** seÃ§ersin.\n",
    "\n",
    "* EÄŸer `p >= eÅŸik` â‡’ **1 (Ä°njury)**, deÄŸilse **0**.\n",
    "* **VarsayÄ±lan** genellikle **0.50**â€™dir, ama bu **sabit** olmak zorunda deÄŸil.\n",
    "\n",
    "Niye Ã¶nemli?\n",
    "\n",
    "* **Precisionâ€“Recall** dengesini ve **F1**, **hata maliyetlerini** doÄŸrudan etkiler. Ã–rn. â€œ**kaÃ§Ä±rmayalÄ±m**â€ (high recall) istiyorsan **eÅŸiÄŸi dÃ¼ÅŸÃ¼rÃ¼rsÃ¼n**; â€œ**yanlÄ±ÅŸ alarm vermeyelim**â€ (high precision) istiyorsan **eÅŸiÄŸi yÃ¼kseltirsin**.\n",
    "* EÄŸitim sÄ±rasÄ±nda **model â€œeÅŸikâ€ Ã¶ÄŸrenmez**; yalnÄ±zca olasÄ±lÄ±k Ã¼retir. **EÅŸik**, senin **iÅŸ kuralÄ±n**dÄ±r (post-processing karar kuralÄ±).\n",
    "\n",
    "Niye kaydediyoruz?\n",
    "\n",
    "* **TutarlÄ±lÄ±k**: Ãœretimde/raporlarda **aynÄ± karar noktasÄ±nÄ±** kullanmak iÃ§in (bugÃ¼n 0.30, yarÄ±n 0.50 olmasÄ±n).\n",
    "* **Ä°zlenebilirlik**: â€œBu model v1.2, **eÅŸik=0.30** ile Ã§alÄ±ÅŸÄ±yorâ€ diyebilmek.\n",
    "* **Esneklik**: EÅŸiÄŸi **modeli yeniden eÄŸitmeden** deÄŸiÅŸtirebilirsin (Ã¶r. sahada Ã§ok alarm geliyorsa 0.30â†’0.40).\n",
    "\n",
    "EÅŸiÄŸi nasÄ±l seÃ§erim?\n",
    "\n",
    "* **F1â€™i maksimize et** (senin koddaki gibi): hem precision hem recall dengesi.\n",
    "* **Youdenâ€™s J / ROC** (TPRâ€“FPR farkÄ±nÄ± maksimize et): sÄ±nÄ±f maliyetleri benzerse iyi baÅŸlangÄ±Ã§.\n",
    "* **Ä°ÅŸ kuralÄ± hedefi**: â€œRecall â‰¥ 0.95 olsunâ€ ya da â€œPrecision â‰¥ 0.90 olsunâ€ gibi kÄ±sÄ±tlarla PR eÄŸrisinden eÅŸik seÃ§.\n",
    "* **Maliyet tabanlÄ±**: FP, FN maliyetlerini ver; beklenen maliyeti minimize eden eÅŸiÄŸi seÃ§.\n",
    "* **Kalibrasyon**: OlasÄ±lÄ±klar iyi kalibre deÄŸilse (Platt/Isotonic), Ã¶nce kalibre et, sonra eÅŸiÄŸi seÃ§.\n",
    "\n",
    "KÄ±sa Ã¶rnekler (senin yapÄ±na uygun):\n",
    "\n",
    "```python\n",
    "# 1) F1â€™i maksimize eden eÅŸik\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def best_threshold_f1(y_true, y_prob):\n",
    "    ts = np.linspace(0.01, 0.99, 99)\n",
    "    best_t, best_s = 0.5, -1\n",
    "    for t in ts:\n",
    "        s = f1_score(y_true, (y_prob >= t).astype(int), zero_division=0)\n",
    "        if s > best_s: best_s, best_t = s, t\n",
    "    return best_t, best_s\n",
    "\n",
    "t_star, s_star = best_threshold_f1(y_valid, model.predict(X_valid_p).ravel())\n",
    "print(\"F1-opt eÅŸik:\", round(t_star, 2), \"F1:\", round(s_star, 3))\n",
    "```\n",
    "\n",
    "```python\n",
    "# 2) \"Precision â‰¥ 0.90\" ÅŸartÄ±yla en yÃ¼ksek recall'u veren eÅŸik\n",
    "prec, rec, thr = precision_recall_curve(y_valid, model.predict(X_valid_p).ravel())\n",
    "target_prec = 0.90\n",
    "candidates = np.where(prec[:-1] >= target_prec)[0]  # son eleman thr ile hizalÄ± deÄŸil\n",
    "i = candidates[np.argmax(rec[candidates])] if len(candidates) else np.argmax(prec[:-1])\n",
    "t_star = thr[i]\n",
    "print(\"Precisionâ‰¥0.90 iÃ§in eÅŸik:\", round(t_star, 2), \"Recall:\", round(rec[i], 3))\n",
    "```\n",
    "\n",
    "Kaydet/YÃ¼kle (eÅŸik bir model parametresi deÄŸildir; **ayrÄ± meta** olarak tutulur):\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# kaydetme\n",
    "joblib.dump({\"threshold\": float(t_star), \"version\": \"v1.0\"}, \"decision_threshold.joblib\")\n",
    "\n",
    "# yÃ¼kleme ve kullanma\n",
    "meta = joblib.load(\"decision_threshold.joblib\")\n",
    "th = meta[\"threshold\"]\n",
    "y_pred = (model.predict(X_test_p).ravel() >= th).astype(int)\n",
    "```\n",
    "\n",
    "Ã–zet:\n",
    "\n",
    "* **EÅŸik**, olasÄ±lÄ±k â†’ sÄ±nÄ±f dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in **karar kuralÄ±n**; **modelin parÃ§asÄ± deÄŸildir**.\n",
    "* **SeÃ§imi**, **hedef metriklerine** ve **iÅŸ maliyetlerine** baÄŸlÄ±dÄ±r.\n",
    "* **Kaydetmek**, Ã¼retimde **istikrar** ve **tekrar edilebilirlik** saÄŸlar; gerektiÄŸinde **tek baÅŸÄ±na ayarlanabilir**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8837d6-7cd7-4f48-9e15-d7a2d4efdac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
