{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9948d022-9a54-4b1e-afc2-cd8c40d8fb03",
   "metadata": {},
   "source": [
    "süper — eğitim çıktıların gayet mantıklı 👌 şimdi iki şeyi yapalım:\n",
    "\n",
    "1. Kodu parça parça, **“neden yaptık?”** diye açıklayayım (özellikle *Bernoulli–Bernoulli RBM* kısmı).\n",
    "2. “**Kullanıcıya film önerisi nasıl alırım?**” için net örnek sorgu kodu vereyim (başlıklarıyla beraber).\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Kodun Mantığı — Adım Adım\n",
    "\n",
    "## (a) Veri → Kullanıcı×Film matrisi → Binarizasyon\n",
    "\n",
    "* MovieLens dosyalarını `user, item, rating` olarak okuyoruz; sonra her kullanıcı için film sayısı uzunluğunda bir vektör oluşturuyoruz.\n",
    "* **Binarize etme:**\n",
    "\n",
    "  * 0 → **bilinmiyor** (kullanıcı o filme hiç puan vermemiş) → `-1` ile işaretliyoruz (maskede “eğitme”).\n",
    "  * 1–2 → **beğenmedi** → `0`\n",
    "  * 3–5 → **beğendi** → `1`\n",
    "* Neden? RBM görünür birimleri **Bernoulli (0/1)** kabul ediyor; yani “bu kullanıcı bu filmi sever mi?” sorusuna ikili bir cevap.\n",
    "\n",
    "## (b) RBM: Bernoulli–Bernoulli nedir?\n",
    "\n",
    "* **Görünür katman** $v \\in {0,1}^{N_\\text{items}}$: her film için 0/1 (sevmez/sever).\n",
    "* **Gizli katman** $h \\in {0,1}^{N_\\text{hidden}}$: filmler arasındaki **latent faktörleri** temsil eder (ör. “bilimkurgu sevgisi”, “romantik komedi teması” gibi).\n",
    "* Enerji fonksiyonu:\n",
    "\n",
    "  $$\n",
    "  E(v,h) = - v^\\top W^\\top h - b^\\top v - a^\\top h\n",
    "  $$\n",
    "* Koşullu olasılıklar (bağımsız Bernoulli):\n",
    "\n",
    "  * $p(h=1 \\mid v) = \\sigma(v W^\\top + a)$\n",
    "  * $p(v=1 \\mid h) = \\sigma(h W + b)$\n",
    "* Dolayısıyla `sample_h(v)` ve `sample_v(h)` fonksiyonlarında **sigmoid** ile olasılık hesaplanıp gerekirse Bernoulli örnekleniyor.\n",
    "\n",
    "## (c) Contrastive Divergence (CD-k)\n",
    "\n",
    "* **Amaç:** Gerçek verinin ortak aktivasyonunu ⟨v·hᵀ⟩ ile, modelin kendi ürettiği örneklerin ortak aktivasyonunu ⟨v'·h'ᵀ⟩ **yaklaştırmak**.\n",
    "* Adımlar:\n",
    "\n",
    "  1. Gerçek veri $v_0$ → $h_0 \\sim p(h\\mid v_0)$\n",
    "  2. $k$ adım Gibbs zinciri: $h\\to v \\to h \\to \\dots$\n",
    "  3. Güncelleme:\n",
    "\n",
    "     $$\n",
    "     \\Delta W \\propto \\langle v_0 h_0^\\top\\rangle - \\langle v_k h_k^\\top\\rangle\n",
    "     $$\n",
    "* Biz `update` içinde bunu **mini-batch ortalama**, **öğrenme oranı**, **momentum** ve **weight decay** ile yapıyoruz:\n",
    "\n",
    "  * **Momentum**: titreşimi azaltır, daha kararlı güncelleme.\n",
    "  * **Weight decay (L2)**: aşırı ezberlemeyi önler.\n",
    "\n",
    "## (d) Maskeli eğitim (bilinmeyenleri taşıma)\n",
    "\n",
    "* Veri matriksinde **bilinmeyen** girişleri `-1` ile işaretledik.\n",
    "* CD içinde görünür örneği güncellerken **yalnızca bilinen (0 veya 1)** pozisyonlarda güncelliyoruz:\n",
    "\n",
    "  ```python\n",
    "  mask = (v0 >= 0).float()\n",
    "  vk = v0 * (1 - mask) + vk_sample * mask\n",
    "  ```\n",
    "\n",
    "  Böylece “kullanıcı hakkında bilmediğimiz filmler” **öğretim sinyali** üretmiyor (gürültü katmıyor).\n",
    "\n",
    "## (e) Rekonstrüksiyon hatası\n",
    "\n",
    "* Eğitim ve testte raporladığın “**reconstruction loss**”, **bilinen** girdilerde `|v0 - v_recon|`’un ortalaması.\n",
    "* Bu, RBM’nin “gördüğünü geri yazma kapasitesini” ölçer; **öneri kalitesinin** birebir karşılığı değildir. O yüzden ayrıca **Precision\\@K / Recall\\@K** veriyoruz (sıralama kalitesi).\n",
    "\n",
    "## (f) Precision\\@10 / Recall\\@10\n",
    "\n",
    "* Her kullanıcı için modelin verdiği **olasılık skorlarına** göre **en iyi 10 film** seçiyoruz.\n",
    "* **Precision\\@10:** Bu 10’luk listenin kaç tanesi testte gerçekten pozitif (beğendi)?\n",
    "* **Recall\\@10:** Testteki tüm pozitiflerinden kaçını ilk 10’da yakaladın?\n",
    "\n",
    "---\n",
    "\n",
    "# 2) “Kullanıcıya film önerisi” — nasıl sorgularım?\n",
    "\n",
    "Aşağıdaki kod, **tek bir kullanıcı** için **top-K öneriyi** verir.\n",
    "\n",
    "* Eğitimde gördüğü pozitifleri listeden **hariç** tutuyoruz (yeni öneri istiyoruz).\n",
    "* Sonucu **film başlıklarıyla** döndürüyoruz.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1) Film başlıklarını oku (ml-1m için)\n",
    "# movies.dat biçimi: MovieID::Title::Genres\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n",
    "movies.columns = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "# 2) Yardımcı: kullanıcı vektörünü al (binarize edilmiş train_bin'den)\n",
    "#    train_bin: (nb_users, nb_items) numpy float32; 1=pozitif, 0=negatif, -1=bilinmiyor\n",
    "def get_user_vector(user_id_1_based, train_bin):\n",
    "    # RBM kodunda kullanıcı indeksleri 0-bazlı; MovieLens ise 1-bazlı idi\n",
    "    return train_bin[user_id_1_based - 1].copy()\n",
    "\n",
    "# 3) Modelden olasılık skorlarını üret (p(v=1|h))\n",
    "@torch.no_grad()\n",
    "def rbm_predict_proba_for_user(rbm, user_vec_np):\n",
    "    # user_vec_np: shape (nb_items,), değerler {-1,0,1}\n",
    "    v = torch.tensor(user_vec_np, dtype=torch.float32, device=rbm.W.device).unsqueeze(0)  # (1, nv)\n",
    "    ph, _ = rbm.sample_h(v)\n",
    "    pv, _ = rbm.sample_v(ph)   # (1, nv)\n",
    "    return pv.squeeze(0).cpu().numpy()  # (nv,)\n",
    "\n",
    "# 4) Tek kullanıcı için top-K öneri\n",
    "def recommend_topk_for_user(user_id_1b, K, rbm, train_bin, movies_df):\n",
    "    user_vec = get_user_vector(user_id_1b, train_bin)\n",
    "    proba = rbm_predict_proba_for_user(rbm, user_vec)\n",
    "\n",
    "    # Zaten kullanıcının pozitif verdiği filmleri öneriden çıkar (yeni öneri)\n",
    "    already_pos = np.where(user_vec == 1.0)[0]\n",
    "    proba[already_pos] = -1e9\n",
    "\n",
    "    # (Opsiyonel) açıkça 0 verdiği (beğenmediği) filmleri de çıkarabilirsin:\n",
    "    # already_neg = np.where(user_vec == 0.0)[0]\n",
    "    # proba[already_neg] = -1e9\n",
    "\n",
    "    topk_idx = np.argsort(proba)[-K:][::-1]\n",
    "    # MovieID’ler 1-bazlı olduğu için +1\n",
    "    rec_movie_ids = (topk_idx + 1)\n",
    "\n",
    "    # Başlıkları eşleştir\n",
    "    rec = movies_df[movies_df[\"movie_id\"].isin(rec_movie_ids)][[\"movie_id\",\"title\",\"genres\"]]\n",
    "    # Sıralamayı proba’ya göre yapalım\n",
    "    order = {mid: proba[mid-1] for mid in rec_movie_ids}\n",
    "    rec = rec.sort_values(by=\"movie_id\", key=lambda s: s.map(order), ascending=False)\n",
    "    rec[\"score\"] = rec[\"movie_id\"].map(order)\n",
    "    return rec.reset_index(drop=True)\n",
    "\n",
    "# --- Örnek kullanım:\n",
    "user_id = 42\n",
    "K = 10\n",
    "recs = recommend_topk_for_user(user_id, K, rbm, train_bin, movies)\n",
    "print(recs)\n",
    "```\n",
    "\n",
    "> Eğer ml-100k kullanıyorsan film meta dosyası `u.item` (ayrı format). Onu da `sep=\"|\"` ile okuyup `movie_id → title` eşleştirmesi yapabilirsin. Temel mantık aynı.\n",
    "\n",
    "---\n",
    "\n",
    "## Sık sorulan ikililer\n",
    "\n",
    "**Bernoulli–Bernoulli** ne demek tekrar?\n",
    "→ Hem görünür birimler (filmler) hem de gizli birimler (faktörler) **ikili (0/1)** olarak modelleniyor; koşullu dağılımlar **sigmoid**.\n",
    "\n",
    "**Reconstruction loss iyi gidiyor ama Precision\\@10 düşük kalırsa?**\n",
    "→ Normal; rekonstrüksiyon “yeniden yazma” ölçüsü. **Öneri** için sıralama metriklerini (Precision/Recall\\@K, MAP, NDCG) optimize eden yöntemler (BPR, WARP, NCF) çoğu zaman daha yüksek olur. RBM burada **temel davranış öğrenmeyi** gösterir.\n",
    "\n",
    "**Skoru nasıl yükseltirim?**\n",
    "\n",
    "* **nh** (gizli birim sayısı) ↑: 64/128/256 dene.\n",
    "* **CD k**: 1→5→10 karşılaştır.\n",
    "* **lr, momentum, weight\\_decay** küçük grid-search.\n",
    "* **Epoch** ↑ (erken durdurma ile).\n",
    "* **Veri ön işleme:** Kullanıcı/film başına min etkileşim eşiği (çok seyrek kullanıcı/film filtrele).\n",
    "* **Hybrid**: İçerik özellikleri ekle (film türü, yıla göre bias vb.) → “görünür”ü çok-logit (softmax) olarak modellemek gelişmiş konu; sıradaki adım olabilir.\n",
    "\n",
    "**Cold-start (yeni kullanıcı/film)?**\n",
    "→ RBM gibi saf etkileşim temelli yöntemlerde zordur. İçerik tabanlı özellikler (film genre, yıl, oyuncular) veya **meta-öğrenme** gerekir.\n",
    "\n",
    "---\n",
    "\n",
    "## Sonuçları nasıl yorumlamalı?\n",
    "\n",
    "* **Train recon loss ↓**: model veriyi daha iyi yeniden kuruyor; yakınsama var.\n",
    "* **Test recon loss ≈ 0.27**: makul.\n",
    "* **Precision\\@10 ≈ 0.10, Recall\\@10 ≈ 0.027** (ml-100k için başlangıç seviyesi normaldir).\n",
    "\n",
    "  * P\\@10 = %10 → ilk 10 öneride ort. 1 tanesi gerçekten pozitif.\n",
    "  * R\\@10 = %2.7 → kullanıcının tüm pozitiflerinden küçük bir kısmı yakalanıyor.\n",
    "* Bu metrikleri yukarıdaki **tuning** adımlarıyla yavaş yavaş yükseltebilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "hazırsan: istersen **ml-100k için film başlığı eşleştirme** (u.item formatı) örneğini de ayrıca atayım, ya da **Goodbooks-10k** gibi başka bir veri setine aynı RBM pipeline’ını uyarlayalım.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f7f57-4f39-4388-8ab4-d28d92e528fc",
   "metadata": {},
   "source": [
    "Kesinlikle hayır—Boltzmann makineleri (özellikle **RBM**) sadece film önerileri için değildir. “**Kullanıcı–öğe etkileşimi**” olan **her** alanda (alışveriş, müzik, kitap, restoran, oyun, haber vb.) **ikili tercih / implicit feedback** üretip öneri yapılabilir. Ayrıca RBM’ler generatif/densite modellemede (ör. binarize MNIST), anomali tespitinde ve özellik çıkarımında da kullanılır.\n",
    "\n",
    "Aşağıya önce veri seti önerilerini, ardından elindeki MovieLens kodunun **daha sağlam** bir sürümünü (öğrenme oranı, momentum, v.b. ile) ve değerlendirmenin nasıl yapılacağını bıraktım.\n",
    "\n",
    "---\n",
    "\n",
    "# ✅ RBM ile çalışabileceğin veri setleri\n",
    "\n",
    "## Öneri / kullanıcı–öğe etkileşimi\n",
    "\n",
    "* **MovieLens** (ml-100k, ml-1m, ml-20m): Klasik benchmark; filmler için puanlar.\n",
    "* **Goodbooks-10k**: Kitap puanları – kitap önerisi.\n",
    "* **Jester**: Fıkra şakalarına verilen dereceler – RBM ile iyi çalışır.\n",
    "* **Last.fm / Million Song Dataset**: Müzik oynatma ve etkileşim – dinleme tabanlı öneri.\n",
    "* **Amazon Reviews** (çeşitli kategoriler): Ürün–kullanıcı puan/yorumları – “beğendim/beğenmedim”e binarize edilebilir.\n",
    "* **Yelp**: Restoran/işletme puanları – yemek/yer önerileri.\n",
    "* **Steam / Games**: Oyun sahiplikleri/incelemeleri – oyun önerisi.\n",
    "* **Book-Crossing**: Kitap rating’leri – kitap önerisi.\n",
    "\n",
    "> Ortak fikir: **kullanıcı × öğe** matrisini **binarize** et (örn. rating ≥ 3 → 1, yoksa 0; “bilinmiyor”ları -1 ile maskele) ve RBM’yi **Bernoulli görünür** birimlerle kur.\n",
    "\n",
    "## Öneri dışı (RBM’nin başka alanları)\n",
    "\n",
    "* **Binarize MNIST** (0/1 piksel): Generatif modelleme & özellik çıkarım.\n",
    "* **Tıklama/görüntüleme günlükleri (clickstream)**: İçerik/ürün önerisi.\n",
    "* **Kurumsal erişim logları**: RBM ile temel yoğunluk modeli → **anomali skoru** (alışılmadık oturumlar).\n",
    "\n",
    "---\n",
    "\n",
    "# 🧠 RBM kısaca (neden işe yarıyor?)\n",
    "\n",
    "* **İkili görünür birimler** (v) ve **ikili gizli birimler** (h) arasında iki katmanlı **enerji tabanlı** model.\n",
    "* **Contrastive Divergence (CD-k)** ile eğitim:\n",
    "\n",
    "  1. Veri görünür v₀ → h \\~ p(h|v₀)\n",
    "  2. h → vₖ \\~ p(v|h) (k adım Gibbs)\n",
    "  3. Ağırlık güncelle: ΔW ∝ ⟨v₀h₀ᵀ⟩ − ⟨vₖhₖᵀ⟩ (öğrenme oranı, momentum, reg. ile)\n",
    "\n",
    "Senin eğitim kodun “çekirdek” olarak doğru ama **öğrenme oranı, momentum, regülarizasyon** yok; ayrıca **değerlendirme** olarak sadece “rekonstrüksiyon hatası” bakıyor. Aşağıda iyileştirilmiş, **PyTorch** ile çalışan bir RBM iskeleti var.\n",
    "\n",
    "---\n",
    "\n",
    "# 🧩 MovieLens (ml-100k) için iyileştirilmiş RBM (PyTorch)\n",
    "\n",
    "> Not: Bu sürüm **öğrenme oranı, momentum, weight decay** içerir; **CD-k** uygular; **maskeli kayıp** kullanır. Ayrıca **Precision\\@K / Recall\\@K** örneği var ki öneri için daha anlamlıdır.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Veri yükleme (ml-100k split)\n",
    "train = pd.read_csv(\"ml-100k/u1.base\", delimiter=\"\\t\", header=None, names=[\"user\",\"item\",\"rating\",\"ts\"])\n",
    "test  = pd.read_csv(\"ml-100k/u1.test\",  delimiter=\"\\t\", header=None, names=[\"user\",\"item\",\"rating\",\"ts\"])\n",
    "\n",
    "nb_users  = max(train.user.max(), test.user.max())\n",
    "nb_items  = max(train.item.max(), test.item.max())\n",
    "\n",
    "def to_user_item_matrix(df, nb_users, nb_items):\n",
    "    X = np.zeros((nb_users, nb_items), dtype=np.float32)\n",
    "    for u, it, r, _ in df.values:\n",
    "        X[u-1, it-1] = r\n",
    "    return X\n",
    "\n",
    "train_mat = to_user_item_matrix(train, nb_users, nb_items)\n",
    "test_mat  = to_user_item_matrix(test,  nb_users, nb_items)\n",
    "\n",
    "# 2) Binarize + mask\n",
    "#  rating == 0 -> bilinmiyor (-1); 1-2 -> 0; 3-5 -> 1\n",
    "def binarize(x):\n",
    "    y = x.copy()\n",
    "    y[y == 0]  = -1.0\n",
    "    y[(y==1) | (y==2)] = 0.0\n",
    "    y[y >= 3]  = 1.0\n",
    "    return y\n",
    "\n",
    "train_bin = binarize(train_mat)\n",
    "test_bin  = binarize(test_mat)\n",
    "\n",
    "train_t = torch.tensor(train_bin, device=device)\n",
    "test_t  = torch.tensor(test_bin,  device=device)\n",
    "\n",
    "# 3) RBM tanımı (Bernoulli-Bernoulli)\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, nv, nh):\n",
    "        super().__init__()\n",
    "        # W: nh x nv (PyTorch param değil; manuel güncelleyeceğiz)\n",
    "        self.W = torch.randn(nh, nv, device=device) * 0.01\n",
    "        self.hbias = torch.zeros(1, nh, device=device)\n",
    "        self.vbias = torch.zeros(1, nv, device=device)\n",
    "\n",
    "    def sample_h(self, v):\n",
    "        # p(h=1|v) = sigmoid(v W^T + hbias)\n",
    "        prob = torch.sigmoid(v @ self.W.t() + self.hbias)\n",
    "        return prob, torch.bernoulli(prob)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        # p(v=1|h) = sigmoid(h W + vbias)\n",
    "        prob = torch.sigmoid(h @ self.W + self.vbias)\n",
    "        return prob, torch.bernoulli(prob)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self, v0, vk, ph0, phk, lr=0.01, momentum=0.5, weight_decay=1e-4,\n",
    "               vW=None, vh=None, vv=None):\n",
    "        # momentum buffer'ları\n",
    "        if vW is None:\n",
    "            vW = torch.zeros_like(self.W)\n",
    "            vh = torch.zeros_like(self.hbias)\n",
    "            vv = torch.zeros_like(self.vbias)\n",
    "\n",
    "        dW = (ph0.t() @ v0 - phk.t() @ vk) / v0.size(0)  # ortalama\n",
    "        db = torch.sum(v0 - vk, dim=0, keepdim=True) / v0.size(0)\n",
    "        da = torch.sum(ph0 - phk, dim=0, keepdim=True) / v0.size(0)\n",
    "\n",
    "        # weight decay (L2 benzeri)\n",
    "        dW -= weight_decay * self.W\n",
    "\n",
    "        # momentum güncellemesi\n",
    "        vW = momentum * vW + lr * dW\n",
    "        vv = momentum * vv + lr * db\n",
    "        vh = momentum * vh + lr * da\n",
    "\n",
    "        self.W     += vW\n",
    "        self.vbias += vv\n",
    "        self.hbias += vh\n",
    "        return vW, vh, vv\n",
    "\n",
    "nv, nh = nb_items, 128\n",
    "rbm = RBM(nv, nh)\n",
    "\n",
    "# 4) Mini-batch eğitim (CD-k)\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "k = 5          # CD-k adımı\n",
    "lr = 0.05\n",
    "momentum = 0.5\n",
    "weight_decay = 1e-4\n",
    "\n",
    "dataset = TensorDataset(train_t)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "vW = vh = vv = None\n",
    "for epoch in range(1, epochs+1):\n",
    "    running = 0.0\n",
    "    cnt = 0\n",
    "    for (v0,) in loader:\n",
    "        # v0: (B, nv)\n",
    "        vk = v0.clone()\n",
    "        # mask: bilinmeyenler (-1) bu pozisyonları koru\n",
    "        mask = (v0 >= 0).float()\n",
    "\n",
    "        ph0, _ = rbm.sample_h(v0)\n",
    "        for _ in range(k):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            pvk, vk_sample = rbm.sample_v(hk)\n",
    "            # bilinmeyen pozisyonları (mask==0) v0’dan taşımayız; sadece bilinenleri güncelliyoruz\n",
    "            vk = v0 * (1 - mask) + vk_sample * mask\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "        vW, vh, vv = rbm.update(v0, vk, ph0, phk, lr, momentum, weight_decay, vW, vh, vv)\n",
    "\n",
    "        # rekonstrüksiyon hatası: sadece bilinenlerde\n",
    "        loss = torch.mean(torch.abs(v0[mask.bool()] - vk[mask.bool()]))\n",
    "        running += loss.item()\n",
    "        cnt += 1\n",
    "    print(f\"Epoch {epoch:02d} | train recon loss: {running/cnt:.4f}\")\n",
    "\n",
    "# 5) Test rekonstrüksiyon hatası\n",
    "with torch.no_grad():\n",
    "    v = train_t  # görünür başlangıç olarak train’i kullan (standart yaklaşım)\n",
    "    ph, _ = rbm.sample_h(v)\n",
    "    pv, _ = rbm.sample_v(ph)\n",
    "    mask_te = (test_t >= 0).float()\n",
    "    test_loss = torch.mean(torch.abs(test_t[mask_te.bool()] - pv[mask_te.bool()]))\n",
    "    print(\"Test recon loss:\", float(test_loss))\n",
    "```\n",
    "\n",
    "## 🎯 Öneri (top-N) değerlendirmesi — Precision\\@K / Recall\\@K\n",
    "\n",
    "Rekonstrüksiyon hatası “öneri kalitesini” tam yansıtmaz. Aşağıda kullanıcı bazında **pozitif test öğelerini** hedef alıp **Precision\\@10 / Recall\\@10** hesaplayan basit bir örnek var (negatif örnekleri basitçe “0” sayıyoruz; daha adil bir kıyas için “negative sampling” ve “unrated filtreleme” eklenebilir).\n",
    "\n",
    "```python\n",
    "def topk_metrics(train_bin, test_bin, proba, K=10):\n",
    "    # train'de zaten 1 olanları öneriden hariç tutmak istersen maskelersin.\n",
    "    P = []\n",
    "    R = []\n",
    "    for u in range(train_bin.shape[0]):\n",
    "        # testteki pozitifler\n",
    "        pos = np.where(test_bin[u] == 1.0)[0]\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "        scores = proba[u].copy()\n",
    "\n",
    "        # (Opsiyonel) zaten train'de 1 olanları öneriden çıkar\n",
    "        already_pos = np.where(train_bin[u] == 1.0)[0]\n",
    "        scores[already_pos] = -1e9\n",
    "\n",
    "        topk = np.argsort(scores)[-K:][::-1]\n",
    "        hit = len(set(topk) & set(pos))\n",
    "        P.append(hit / K)\n",
    "        R.append(hit / len(pos))\n",
    "    return float(np.mean(P)), float(np.mean(R))\n",
    "\n",
    "with torch.no_grad():\n",
    "    ph, _ = rbm.sample_h(train_t)\n",
    "    pv, _ = rbm.sample_v(ph)      # öneri olasılıkları ~ p(v=1|h)\n",
    "    proba = pv.detach().cpu().numpy()\n",
    "    P10, R10 = topk_metrics(train_bin, test_bin, proba, K=10)\n",
    "    print(f\"Precision@10={P10:.4f} | Recall@10={R10:.4f}\")\n",
    "```\n",
    "\n",
    "> Daha adil değerlendirme için: “bilinmeyenleri” negatif sayma; her kullanıcı için test pozitiflerine karşı **rastgele negatif örnekle** ve **AUC / MAP / NDCG** gibi metrikler kullan.\n",
    "\n",
    "---\n",
    "\n",
    "## SSS (kısa notlar)\n",
    "\n",
    "* **RBM sadece MovieLens için mi?**\n",
    "  Hayır. Her **user–item** matrisinde (müzik, kitap, ürün, restoran, oyun…) **binarize** edip RBM ile **implicit öneri** yapılabilir.\n",
    "\n",
    "* **Neden rating’leri binarize ediyoruz?**\n",
    "  Bu RBM **Bernoulli görünür** birimler varsayıyor. Çok seviyeli rating için **Gaussian–Bernoulli RBM** veya **softmax görünür** (her item için puan sınıfları) kullanılabilir; ama pratikte “beğendi/beğenmedi (implicit)” iyi çalışır.\n",
    "\n",
    "* **CD-k kaç olmalı?**\n",
    "  1–10 arası yaygın. k↑ → daha iyi yakınsama ama daha yavaş. Genelde **CD-1..CD-5** yeterli.\n",
    "\n",
    "* **Rekonstrüksiyon kaybı neden yeterli değil?**\n",
    "  Önerinin kalitesi **sıralama** ile ölçülür (Precision\\@K, Recall\\@K, MAP, NDCG). O yüzden ekledik.\n",
    "\n",
    "* **Modern alternatifler?**\n",
    "  RBM eğitici bir temel. Pratikte **Matrix Factorization (BPR/ALS)**, **Neural CF**, **AutoEncoder (VAE/DAE)**, **LightFM** ve **implicit** kütüphanesi gibi yöntemler sık kullanılıyor.\n",
    "\n",
    "---\n",
    "\n",
    "İstersen yukarıdaki kodu **kendi veri setin** için uyarlayalım (ör. Goodbooks-10k veya Amazon). “Veriyi nasıl okuyalım, nasıl binarize edelim, split nasıl olsun?” diye beraber net bir pipeline çıkarırız.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57624c-4aff-494e-bbe2-7a3e12288d51",
   "metadata": {},
   "source": [
    "süper — eğitim çıktıların gayet mantıklı 👌 şimdi iki şeyi yapalım:\n",
    "\n",
    "1. Kodu parça parça, **“neden yaptık?”** diye açıklayayım (özellikle *Bernoulli–Bernoulli RBM* kısmı).\n",
    "2. “**Kullanıcıya film önerisi nasıl alırım?**” için net örnek sorgu kodu vereyim (başlıklarıyla beraber).\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Kodun Mantığı — Adım Adım\n",
    "\n",
    "## (a) Veri → Kullanıcı×Film matrisi → Binarizasyon\n",
    "\n",
    "* MovieLens dosyalarını `user, item, rating` olarak okuyoruz; sonra her kullanıcı için film sayısı uzunluğunda bir vektör oluşturuyoruz.\n",
    "* **Binarize etme:**\n",
    "\n",
    "  * 0 → **bilinmiyor** (kullanıcı o filme hiç puan vermemiş) → `-1` ile işaretliyoruz (maskede “eğitme”).\n",
    "  * 1–2 → **beğenmedi** → `0`\n",
    "  * 3–5 → **beğendi** → `1`\n",
    "* Neden? RBM görünür birimleri **Bernoulli (0/1)** kabul ediyor; yani “bu kullanıcı bu filmi sever mi?” sorusuna ikili bir cevap.\n",
    "\n",
    "## (b) RBM: Bernoulli–Bernoulli nedir?\n",
    "\n",
    "* **Görünür katman** $v \\in {0,1}^{N_\\text{items}}$: her film için 0/1 (sevmez/sever).\n",
    "* **Gizli katman** $h \\in {0,1}^{N_\\text{hidden}}$: filmler arasındaki **latent faktörleri** temsil eder (ör. “bilimkurgu sevgisi”, “romantik komedi teması” gibi).\n",
    "* Enerji fonksiyonu:\n",
    "\n",
    "  $$\n",
    "  E(v,h) = - v^\\top W^\\top h - b^\\top v - a^\\top h\n",
    "  $$\n",
    "* Koşullu olasılıklar (bağımsız Bernoulli):\n",
    "\n",
    "  * $p(h=1 \\mid v) = \\sigma(v W^\\top + a)$\n",
    "  * $p(v=1 \\mid h) = \\sigma(h W + b)$\n",
    "* Dolayısıyla `sample_h(v)` ve `sample_v(h)` fonksiyonlarında **sigmoid** ile olasılık hesaplanıp gerekirse Bernoulli örnekleniyor.\n",
    "\n",
    "## (c) Contrastive Divergence (CD-k)\n",
    "\n",
    "* **Amaç:** Gerçek verinin ortak aktivasyonunu ⟨v·hᵀ⟩ ile, modelin kendi ürettiği örneklerin ortak aktivasyonunu ⟨v'·h'ᵀ⟩ **yaklaştırmak**.\n",
    "* Adımlar:\n",
    "\n",
    "  1. Gerçek veri $v_0$ → $h_0 \\sim p(h\\mid v_0)$\n",
    "  2. $k$ adım Gibbs zinciri: $h\\to v \\to h \\to \\dots$\n",
    "  3. Güncelleme:\n",
    "\n",
    "     $$\n",
    "     \\Delta W \\propto \\langle v_0 h_0^\\top\\rangle - \\langle v_k h_k^\\top\\rangle\n",
    "     $$\n",
    "* Biz `update` içinde bunu **mini-batch ortalama**, **öğrenme oranı**, **momentum** ve **weight decay** ile yapıyoruz:\n",
    "\n",
    "  * **Momentum**: titreşimi azaltır, daha kararlı güncelleme.\n",
    "  * **Weight decay (L2)**: aşırı ezberlemeyi önler.\n",
    "\n",
    "## (d) Maskeli eğitim (bilinmeyenleri taşıma)\n",
    "\n",
    "* Veri matriksinde **bilinmeyen** girişleri `-1` ile işaretledik.\n",
    "* CD içinde görünür örneği güncellerken **yalnızca bilinen (0 veya 1)** pozisyonlarda güncelliyoruz:\n",
    "\n",
    "  ```python\n",
    "  mask = (v0 >= 0).float()\n",
    "  vk = v0 * (1 - mask) + vk_sample * mask\n",
    "  ```\n",
    "\n",
    "  Böylece “kullanıcı hakkında bilmediğimiz filmler” **öğretim sinyali** üretmiyor (gürültü katmıyor).\n",
    "\n",
    "## (e) Rekonstrüksiyon hatası\n",
    "\n",
    "* Eğitim ve testte raporladığın “**reconstruction loss**”, **bilinen** girdilerde `|v0 - v_recon|`’un ortalaması.\n",
    "* Bu, RBM’nin “gördüğünü geri yazma kapasitesini” ölçer; **öneri kalitesinin** birebir karşılığı değildir. O yüzden ayrıca **Precision\\@K / Recall\\@K** veriyoruz (sıralama kalitesi).\n",
    "\n",
    "## (f) Precision\\@10 / Recall\\@10\n",
    "\n",
    "* Her kullanıcı için modelin verdiği **olasılık skorlarına** göre **en iyi 10 film** seçiyoruz.\n",
    "* **Precision\\@10:** Bu 10’luk listenin kaç tanesi testte gerçekten pozitif (beğendi)?\n",
    "* **Recall\\@10:** Testteki tüm pozitiflerinden kaçını ilk 10’da yakaladın?\n",
    "\n",
    "---\n",
    "\n",
    "# 2) “Kullanıcıya film önerisi” — nasıl sorgularım?\n",
    "\n",
    "Aşağıdaki kod, **tek bir kullanıcı** için **top-K öneriyi** verir.\n",
    "\n",
    "* Eğitimde gördüğü pozitifleri listeden **hariç** tutuyoruz (yeni öneri istiyoruz).\n",
    "* Sonucu **film başlıklarıyla** döndürüyoruz.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1) Film başlıklarını oku (ml-1m için)\n",
    "# movies.dat biçimi: MovieID::Title::Genres\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n",
    "movies.columns = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "# 2) Yardımcı: kullanıcı vektörünü al (binarize edilmiş train_bin'den)\n",
    "#    train_bin: (nb_users, nb_items) numpy float32; 1=pozitif, 0=negatif, -1=bilinmiyor\n",
    "def get_user_vector(user_id_1_based, train_bin):\n",
    "    # RBM kodunda kullanıcı indeksleri 0-bazlı; MovieLens ise 1-bazlı idi\n",
    "    return train_bin[user_id_1_based - 1].copy()\n",
    "\n",
    "# 3) Modelden olasılık skorlarını üret (p(v=1|h))\n",
    "@torch.no_grad()\n",
    "def rbm_predict_proba_for_user(rbm, user_vec_np):\n",
    "    # user_vec_np: shape (nb_items,), değerler {-1,0,1}\n",
    "    v = torch.tensor(user_vec_np, dtype=torch.float32, device=rbm.W.device).unsqueeze(0)  # (1, nv)\n",
    "    ph, _ = rbm.sample_h(v)\n",
    "    pv, _ = rbm.sample_v(ph)   # (1, nv)\n",
    "    return pv.squeeze(0).cpu().numpy()  # (nv,)\n",
    "\n",
    "# 4) Tek kullanıcı için top-K öneri\n",
    "def recommend_topk_for_user(user_id_1b, K, rbm, train_bin, movies_df):\n",
    "    user_vec = get_user_vector(user_id_1b, train_bin)\n",
    "    proba = rbm_predict_proba_for_user(rbm, user_vec)\n",
    "\n",
    "    # Zaten kullanıcının pozitif verdiği filmleri öneriden çıkar (yeni öneri)\n",
    "    already_pos = np.where(user_vec == 1.0)[0]\n",
    "    proba[already_pos] = -1e9\n",
    "\n",
    "    # (Opsiyonel) açıkça 0 verdiği (beğenmediği) filmleri de çıkarabilirsin:\n",
    "    # already_neg = np.where(user_vec == 0.0)[0]\n",
    "    # proba[already_neg] = -1e9\n",
    "\n",
    "    topk_idx = np.argsort(proba)[-K:][::-1]\n",
    "    # MovieID’ler 1-bazlı olduğu için +1\n",
    "    rec_movie_ids = (topk_idx + 1)\n",
    "\n",
    "    # Başlıkları eşleştir\n",
    "    rec = movies_df[movies_df[\"movie_id\"].isin(rec_movie_ids)][[\"movie_id\",\"title\",\"genres\"]]\n",
    "    # Sıralamayı proba’ya göre yapalım\n",
    "    order = {mid: proba[mid-1] for mid in rec_movie_ids}\n",
    "    rec = rec.sort_values(by=\"movie_id\", key=lambda s: s.map(order), ascending=False)\n",
    "    rec[\"score\"] = rec[\"movie_id\"].map(order)\n",
    "    return rec.reset_index(drop=True)\n",
    "\n",
    "# --- Örnek kullanım:\n",
    "user_id = 42\n",
    "K = 10\n",
    "recs = recommend_topk_for_user(user_id, K, rbm, train_bin, movies)\n",
    "print(recs)\n",
    "```\n",
    "\n",
    "> Eğer ml-100k kullanıyorsan film meta dosyası `u.item` (ayrı format). Onu da `sep=\"|\"` ile okuyup `movie_id → title` eşleştirmesi yapabilirsin. Temel mantık aynı.\n",
    "\n",
    "---\n",
    "\n",
    "## Sık sorulan ikililer\n",
    "\n",
    "**Bernoulli–Bernoulli** ne demek tekrar?\n",
    "→ Hem görünür birimler (filmler) hem de gizli birimler (faktörler) **ikili (0/1)** olarak modelleniyor; koşullu dağılımlar **sigmoid**.\n",
    "\n",
    "**Reconstruction loss iyi gidiyor ama Precision\\@10 düşük kalırsa?**\n",
    "→ Normal; rekonstrüksiyon “yeniden yazma” ölçüsü. **Öneri** için sıralama metriklerini (Precision/Recall\\@K, MAP, NDCG) optimize eden yöntemler (BPR, WARP, NCF) çoğu zaman daha yüksek olur. RBM burada **temel davranış öğrenmeyi** gösterir.\n",
    "\n",
    "**Skoru nasıl yükseltirim?**\n",
    "\n",
    "* **nh** (gizli birim sayısı) ↑: 64/128/256 dene.\n",
    "* **CD k**: 1→5→10 karşılaştır.\n",
    "* **lr, momentum, weight\\_decay** küçük grid-search.\n",
    "* **Epoch** ↑ (erken durdurma ile).\n",
    "* **Veri ön işleme:** Kullanıcı/film başına min etkileşim eşiği (çok seyrek kullanıcı/film filtrele).\n",
    "* **Hybrid**: İçerik özellikleri ekle (film türü, yıla göre bias vb.) → “görünür”ü çok-logit (softmax) olarak modellemek gelişmiş konu; sıradaki adım olabilir.\n",
    "\n",
    "**Cold-start (yeni kullanıcı/film)?**\n",
    "→ RBM gibi saf etkileşim temelli yöntemlerde zordur. İçerik tabanlı özellikler (film genre, yıl, oyuncular) veya **meta-öğrenme** gerekir.\n",
    "\n",
    "---\n",
    "\n",
    "## Sonuçları nasıl yorumlamalı?\n",
    "\n",
    "* **Train recon loss ↓**: model veriyi daha iyi yeniden kuruyor; yakınsama var.\n",
    "* **Test recon loss ≈ 0.27**: makul.\n",
    "* **Precision\\@10 ≈ 0.10, Recall\\@10 ≈ 0.027** (ml-100k için başlangıç seviyesi normaldir).\n",
    "\n",
    "  * P\\@10 = %10 → ilk 10 öneride ort. 1 tanesi gerçekten pozitif.\n",
    "  * R\\@10 = %2.7 → kullanıcının tüm pozitiflerinden küçük bir kısmı yakalanıyor.\n",
    "* Bu metrikleri yukarıdaki **tuning** adımlarıyla yavaş yavaş yükseltebilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "hazırsan: istersen **ml-100k için film başlığı eşleştirme** (u.item formatı) örneğini de ayrıca atayım, ya da **Goodbooks-10k** gibi başka bir veri setine aynı RBM pipeline’ını uyarlayalım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448271e-a164-48fe-8a3a-5370b11452e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
