{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba40a7c-47dd-4626-b058-f7c7308f6368",
   "metadata": {},
   "source": [
    "Süper—**Credit Card Fraud (ULB)** için SOM egzersizini “baştan sona” tek parça, Jupyter’da çalışır **tam kod** olarak veriyorum.\n",
    "Aşağıdaki betik; veri yükleme → **kimlik kolonu atma** → **ölçekleme** → **SOM eğitimi** → **U-Matrix** → **SOM tabanlı iki skor** (QE ve BMU-fraud-yoğunluğu) → **eşik seçimi (F1-opt / Precision≥x)** → **K-Means karşılaştırma** adımlarını içerir.\n",
    "Her adımın **nedenini** yorum satırlarında belirttim.\n",
    "\n",
    "> Notlar:\n",
    ">\n",
    "> * Dosya adı **`creditcard.csv`** varsayılmıştır.\n",
    "> * `MiniSom` yoksa: `pip install minisom`\n",
    "> * Grafikler için `matplotlib` kullanılıyor.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 0) Kurulum ve log/uyarı ayarları (temizlik)\n",
    "# ===========================================\n",
    "import os, warnings, logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             precision_recall_curve, roc_curve,\n",
    "                             classification_report)\n",
    "\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 1) Veri: Yükle, hedef/özellik ayır, kimlik kolonu at\n",
    "# ===========================================\n",
    "# NEDEN? 'CustomerID' gibi kimlik kolonları davranış bilgisi içermez, uzaklık tabanlı yöntemleri bozar.\n",
    "#       Bu yüzden mutlaka çıkarıyoruz.\n",
    "\n",
    "CSV_PATH = \"creditcard.csv\"   # gerekirse değiştir\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Şekil:\", df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "assert \"Class\" in df.columns, \"Class etiketi bulunamadı\"\n",
    "\n",
    "drop_cols = []\n",
    "for cand in [\"CustomerID\", \"customer_id\", \"ID\", \"id\"]:\n",
    "    if cand in df.columns:\n",
    "        drop_cols.append(cand)\n",
    "\n",
    "y = df[\"Class\"].values.astype(int)\n",
    "X = df.drop(columns=[\"Class\"] + drop_cols)\n",
    "\n",
    "print(\"\\nKullanılan özellik sayısı:\", X.shape[1])\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 2) Ölçekleme (StandardScaler)\n",
    "# ===========================================\n",
    "# NEDEN? SOM öklid mesafesi kullanır; ölçek farkları sonucu bozar.\n",
    "#       Tüm sayısal sütunları standardize ediyoruz (mean=0, std=1).\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/Test böl (etiket sadece değerlendirme için)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Split:\", X_train.shape, X_test.shape,\n",
    "      \" | train fraud rate:\", y_train.mean(), \" | test fraud rate:\", y_test.mean())\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 3) SOM Eğitimi\n",
    "# ===========================================\n",
    "# Grid boyutunu veri büyüklüğüne göre \"sıkı\" tutuyoruz (12x12 / 15x15 iyi başlar).\n",
    "# Sigma: Komşuluk genişliği (1.5-2.0 arası genelde iyi)\n",
    "# Learning rate: 0.5 ile başla, MiniSom iterasyonla düşürür.\n",
    "m, n = 12, 12\n",
    "sigma = 1.8\n",
    "lr = 0.5\n",
    "iterations = 15 * X_train.shape[0]  # 10-20x N_train iyi pratik; hızlı test için 5x seçilebilir\n",
    "\n",
    "som = MiniSom(x=m, y=n, input_len=X_train.shape[1], sigma=sigma, learning_rate=lr,\n",
    "              neighborhood_function='gaussian', random_seed=42)\n",
    "som.random_weights_init(X_train)\n",
    "print(\"SOM init tamam.\")\n",
    "\n",
    "som.train_random(X_train, iterations, verbose=True)\n",
    "print(\"SOM eğitim bitti.\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 4) U-Matrix (Distance Map) Görselleştirme\n",
    "# ===========================================\n",
    "# NEDEN? Hücreler arası mesafe ısı haritası; yüksek mesafeli bölgeler sınır/anomali adacıkları olabilir.\n",
    "u_matrix = som.distance_map()  # (m, n)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(u_matrix.T, cmap=\"bone\", origin=\"lower\")\n",
    "plt.title(\"SOM U-Matrix (Distance Map)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 5) Skor-1: Quantization Error (QE) tabanlı anomaly score\n",
    "# ===========================================\n",
    "# NEDEN? Her örneğin en iyi eşleşen hücre (BMU) ağırlığına uzaklığı = \"ne kadar uymuyor\" = anomali skoru\n",
    "def som_quantization_error(som, x):\n",
    "    w = som.get_weights()       # (m, n, d)\n",
    "    bmu = som.winner(x)         # (i, j)\n",
    "    w_bmu = w[bmu]              # (d,)\n",
    "    return np.linalg.norm(x - w_bmu)\n",
    "\n",
    "scores_qe = np.array([som_quantization_error(som, x) for x in X_test])\n",
    "\n",
    "roc_qe = roc_auc_score(y_test, scores_qe)\n",
    "pr_qe  = average_precision_score(y_test, scores_qe)\n",
    "print(f\"[QE] ROC-AUC: {roc_qe:.4f} | PR-AUC: {pr_qe:.4f}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 6) Skor-2: BMU \"fraud yoğunluğu\" (semi-supervised propensity)\n",
    "# ===========================================\n",
    "# NEDEN? Unsupervised SOM üzerinde, sadece skor fonksiyonunu etiketle kalibre ediyoruz:\n",
    "#       Her BMU hücresi için train set fraud oranını hesapla; testte o hücreye düşenlere bu oranı skor olarak ver.\n",
    "from collections import defaultdict\n",
    "\n",
    "bmu_train = np.array([som.winner(x) for x in X_train])\n",
    "\n",
    "cell_counts = defaultdict(int)\n",
    "cell_fraud  = defaultdict(int)\n",
    "for (cx, cy), lab in zip(bmu_train, y_train):\n",
    "    cell_counts[(cx, cy)] += 1\n",
    "    cell_fraud[(cx, cy)]  += int(lab)\n",
    "\n",
    "cell_rate = {k: (cell_fraud[k] / cell_counts[k]) for k in cell_counts.keys()}\n",
    "\n",
    "bmu_test = np.array([som.winner(x) for x in X_test])\n",
    "scores_prop = np.array([cell_rate.get(tuple(c), 0.0) for c in bmu_test])\n",
    "\n",
    "roc_prop = roc_auc_score(y_test, scores_prop)\n",
    "pr_prop  = average_precision_score(y_test, scores_prop)\n",
    "print(f\"[BMU-Propensity] ROC-AUC: {roc_prop:.4f} | PR-AUC: {pr_prop:.4f}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 7) Skorları birleştirme (opsiyonel basit ortalama)\n",
    "# ===========================================\n",
    "# NEDEN? QE ve Propensity farklı sinyaller taşır; basit bir ensemble çoğu zaman daha iyi sonuç verir.\n",
    "scores_combo = 0.5 * ( (scores_qe - scores_qe.min()) / (scores_qe.ptp()+1e-12) ) + \\\n",
    "               0.5 * ( (scores_prop - scores_prop.min()) / (scores_prop.ptp()+1e-12) )\n",
    "\n",
    "roc_combo = roc_auc_score(y_test, scores_combo)\n",
    "pr_combo  = average_precision_score(y_test, scores_combo)\n",
    "print(f\"[COMBO] ROC-AUC: {roc_combo:.4f} | PR-AUC: {pr_combo:.4f}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 8) Eşik seçimi: PR eğrisinden (F1-opt veya Precision>=x)\n",
    "# ===========================================\n",
    "# NEDEN? \"En anormal %1\" gibi sabit top-k yerine, PR eğrisinden F1'i maksimize eden eşik genelde daha dengeli sonuç verir.\n",
    "\n",
    "def pick_threshold_by_f1(y_true, scores):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, scores)\n",
    "    f1s = 2*prec[:-1]*rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "    i = np.argmax(f1s)\n",
    "    return thr[i], prec[i], rec[i], f1s[i]\n",
    "\n",
    "def pick_threshold_by_precision(y_true, scores, target_p=0.80):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, scores)\n",
    "    idx = np.where(prec[:-1] >= target_p)[0]\n",
    "    if len(idx) == 0:\n",
    "        # hedef precision sağlanmıyorsa F1-opt'a düş\n",
    "        return pick_threshold_by_f1(y_true, scores)\n",
    "    i = idx[np.argmax(rec[idx])]\n",
    "    return thr[i], prec[i], rec[i], 2*prec[i]*rec[i]/(prec[i]+rec[i]+1e-12)\n",
    "\n",
    "# Hangi skorla karar vereceğiz? (QE / PROP / COMBO)\n",
    "chosen = scores_combo  # çoğu zaman COMBO en iyi olur; istersen değiştir: scores_qe veya scores_prop\n",
    "\n",
    "t_f1, p_f1, r_f1, f1_f1 = pick_threshold_by_f1(y_test, chosen)\n",
    "pred_f1 = (chosen >= t_f1).astype(int)\n",
    "\n",
    "print(\"\\n[F1-opt threshold]\")\n",
    "print(\"threshold:\", round(float(t_f1), 6), \"| P:\", round(float(p_f1),3),\n",
    "      \"| R:\", round(float(r_f1),3), \"| F1:\", round(float(f1_f1),3))\n",
    "print(classification_report(y_test, pred_f1, digits=4))\n",
    "\n",
    "# Örnek: Precision ≥ 0.80 şartıyla eşik\n",
    "t_p, p_p, r_p, f1_p = pick_threshold_by_precision(y_test, chosen, target_p=0.80)\n",
    "pred_p = (chosen >= t_p).astype(int)\n",
    "\n",
    "print(\"\\n[Precision>=0.80 threshold]\")\n",
    "print(\"threshold:\", round(float(t_p), 6), \"| P:\", round(float(p_p),3),\n",
    "      \"| R:\", round(float(r_p),3), \"| F1:\", round(float(f1_p),3))\n",
    "print(classification_report(y_test, pred_p, digits=4))\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 9) ROC ve PR eğrileri (seçtiğin skor için)\n",
    "# ===========================================\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_curves(y_true, scores, title_suffix=\"(Combo)\"):\n",
    "    prec, rec, _ = precision_recall_curve(y_true, scores)\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "    ap  = average_precision_score(y_true, scores)\n",
    "    roc = roc_auc_score(y_true, scores)\n",
    "\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title(f\"ROC {title_suffix} | AUC={roc:.3f}\")\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(rec, prec)\n",
    "    plt.title(f\"PR {title_suffix} | AP={ap:.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.grid(alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_curves(y_test, scores_combo, \"(COMBO)\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# ===========================================\n",
    "# 10) K-Means karşılaştırma: Elbow + küme fraud oranları\n",
    "# ===========================================\n",
    "# NEDEN? Gözetimsiz bir referans yöntemle SOM sonuçlarını kıyaslamak için.\n",
    "inertias, ks = [], range(2, 13)\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    km.fit(X_train)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.plot(ks, inertias, marker=\"o\")\n",
    "plt.title(\"K-Means Elbow (Inertia)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"inertia\"); plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "k = 8  # istersen elbow grafiğine göre değiştir\n",
    "km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(X_train)\n",
    "train_k = km.predict(X_train)\n",
    "test_k  = km.predict(X_test)\n",
    "\n",
    "k_rates = {i: (y_train[train_k==i].mean() if (train_k==i).any() else 0.0) for i in range(k)}\n",
    "k_score = np.array([k_rates[c] for c in test_k])\n",
    "\n",
    "print(\"[KMeans-Propensity] ROC-AUC:\", roc_auc_score(y_test, k_score))\n",
    "print(\"[KMeans-Propensity] PR-AUC :\", average_precision_score(y_test, k_score))\n",
    "\n",
    "pd.DataFrame({\"cluster\": list(k_rates.keys()),\n",
    "              \"fraud_rate\": [k_rates[i] for i in k_rates]}).sort_values(\"fraud_rate\", ascending=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Kılavuz (özet)\n",
    "\n",
    "* **Kimlik kolonlarını at** (örn. `CustomerID`)\n",
    "* **Sadece StandardScaler** ile başla (PCA’yı sonra dene)\n",
    "* **SOM’i kompakt kur** (12×12 / 15×15; `sigma≈1.8`, `iter≈10–20×N`)\n",
    "* **İki skor üret:**\n",
    "\n",
    "  * **QE (BMU uzaklığı)** → saf unsupervised anomali sinyali\n",
    "  * **BMU fraud yoğunluğu** → semi-supervised “propensity” sinyali\n",
    "* **Skorları birleştir**, **etikete bakarak eşiği PR eğrisinden seç** (F1-opt veya Precision≥x)\n",
    "* **K-Means** ile kıyasla; istersen **ensemble** yap\n",
    "\n",
    "Kodı çalıştır; çıkan **ROC/PR**, **rapor** ve **fraud-rate kümeleri**’ni paylaş — birlikte hiperparametreleri (harita boyutu/sigma/iterasyon, eşik seçimi, skor birleştirme ağırlıkları) ince ayarlarız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691eda73-8143-436f-8453-06d8442d6550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
