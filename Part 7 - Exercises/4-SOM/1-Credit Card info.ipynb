{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba609da-4ffc-4ae0-b386-623e9540dec0",
   "metadata": {},
   "source": [
    "harika! **Credit Card Fraud (ULB)** ile SOM egzersizini adım adım, Jupyter’da direkt çalışacak şekilde veriyorum. Kod, veriyi yükleme → ölçekleme → (opsiyonel) PCA → **SOM eğitimi** → **U-Matrix görselleştirme** → **Fraud noktalarını haritada gösterme** → **SOM tabanlı anomaly skoru + ROC/PR** → **K-Means + Elbow** akışını kapsar.\n",
    "\n",
    "> Not: Aşağıdaki kod, dosya adının `creditcard.csv` olduğunu varsayar (Kaggle’dan inince öyle geliyor). Eğer farklı klasördeyse PATH’i değiştir.\n",
    "\n",
    "---\n",
    "\n",
    "# 0) Kurulum (gerekirse)\n",
    "\n",
    "```python\n",
    "# (Gerekirse) MiniSom kurulumu\n",
    "# !pip install minisom --quiet\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Kütüphaneler ve uyarıları kısma\n",
    "\n",
    "```python\n",
    "import os, warnings, logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve, classification_report\n",
    "\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 2) Veri yükleme + hızlı bakış\n",
    "\n",
    "```python\n",
    "# CSV dosyasını oku\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "# Sütunlar tipik olarak: ['Time','V1'..'V28','Amount','Class']\n",
    "assert \"Class\" in df.columns, \"Class etiketi bulunamadı\"\n",
    "y = df[\"Class\"].values.astype(int)\n",
    "\n",
    "# Özellik matrisi\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "```\n",
    "\n",
    "**Neden?**\n",
    "\n",
    "* `Class` (0=normal, 1=fraud) etiketi değerlendirme için kalsın; **SOM eğitimi etiketsizdir (unsupervised).**\n",
    "\n",
    "---\n",
    "\n",
    "# 3) Ölçekleme + (Opsiyonel) PCA\n",
    "\n",
    "**Neden?** SOM öklid mesafesiyle çalışır; ölçek farklılıkları sonuçları bozar. PCA gürültüyü azaltıp eğitimi hızlandırabilir.\n",
    "\n",
    "```python\n",
    "# \"Amount\" ve \"Time\" ölçeklenir; V1..V28 zaten PCA-türevi (ama yine de standardization faydalıdır)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Opsiyonel PCA: %95 varyansı koru (dilersen kapatabilirsin)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Orijinal boyut:\", X_scaled.shape[1], \"-> PCA boyutu:\", X_pca.shape[1])\n",
    "```\n",
    "\n",
    "> İlk denemede **PCA açık** bırakmanı öneririm (eğitim hızlanır). İstersen daha sonra PCA’yı kapatıp sadece `X_scaled` ile dene.\n",
    "\n",
    "---\n",
    "\n",
    "# 4) Train/Test böl (etiketi sadece değerlendirme için tutuyoruz)\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5) SOM parametreleri ve eğitim\n",
    "\n",
    "**Neden bu değerler?** 20×20 grid orta boy; `sigma` komşuluk yayılımı, `learning_rate` başlangıç öğrenme hızı. İterasyon sayısını veri boyutuna göre artırıp azaltabilirsin.\n",
    "\n",
    "```python\n",
    "m, n = 20, 20                   # SOM ızgara boyutu (20x20)\n",
    "input_len = X_train.shape[1]    # PCA sonrası özellik sayısı\n",
    "sigma = 2.0\n",
    "lr = 0.5\n",
    "\n",
    "som = MiniSom(x=m, y=n, input_len=input_len, sigma=sigma, learning_rate=lr,\n",
    "              neighborhood_function='gaussian', random_seed=42)\n",
    "\n",
    "som.random_weights_init(X_train)\n",
    "print(\"SOM init tamam.\")\n",
    "\n",
    "# Eğitim (iteration = yaklaşık 10 * num_samples iyi bir başlangıç)\n",
    "iterations = 10 * X_train.shape[0]\n",
    "som.train_random(X_train, iterations, verbose=True)\n",
    "print(\"SOM eğitim bitti.\")\n",
    "```\n",
    "\n",
    "> Daha hızlı deneme için `iterations = 5 * X_train.shape[0]` da yeterli olabilir. Stabil hale gelince artırırsın.\n",
    "\n",
    "---\n",
    "\n",
    "# 6) U-Matrix (distance map) görselleştirme\n",
    "\n",
    "**Neden?** U-Matrix, hücre ağırlıkları arasındaki mesafeleri ısı haritası gibi gösterir. **Yüksek mesafe bölgeleri** genellikle **sınır/anomali** alanlarını işaret eder.\n",
    "\n",
    "```python\n",
    "u_matrix = som.distance_map()  # (m, n)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(u_matrix.T, cmap=\"bone\", origin=\"lower\")\n",
    "plt.title(\"SOM U-Matrix (Distance Map)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 7) Fraud noktalarını harita üzerinde işaretlemek (hızlı bakış)\n",
    "\n",
    "```python\n",
    "# Test verisini BMU'lara (best matching unit) yerleştir\n",
    "bmu_coords = np.array([som.winner(x) for x in X_test])   # (N_test, 2)\n",
    "\n",
    "fraud_idx = np.where(y_test==1)[0]\n",
    "normal_idx = np.where(y_test==0)[0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(u_matrix.T, cmap=\"bone\", origin=\"lower\")\n",
    "plt.scatter(bmu_coords[normal_idx,0], bmu_coords[normal_idx,1], s=3, c=\"tab:blue\", alpha=0.3, label=\"normal\")\n",
    "plt.scatter(bmu_coords[fraud_idx,0],  bmu_coords[fraud_idx,1],  s=8, c=\"tab:red\",  alpha=0.8, label=\"fraud\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"SOM Haritası: Test noktaları (Kırmızı=Fraud)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> Fraud’ların **yüksek U-Matrix bölgelerine** veya belirli hücre adalarına daha çok düşmesi beklenir.\n",
    "\n",
    "---\n",
    "\n",
    "# 8) SOM tabanlı **anomaly score** ve değerlendirme\n",
    "\n",
    "**Fikir:** Her örnek için **BMU’ya uzaklık** (quantization error) bir “anomali skoru”dur. **Ne kadar uzak → o kadar anormal.**\n",
    "\n",
    "```python\n",
    "# Ağırlık matrisinden BMU vektörünü alıp örnekle arasındaki mesafe\n",
    "def som_quantization_error(som, x):\n",
    "    w = som.get_weights()  # (m, n, input_len)\n",
    "    bmu = som.winner(x)\n",
    "    w_bmu = w[bmu]         # (input_len,)\n",
    "    return np.linalg.norm(x - w_bmu)\n",
    "\n",
    "# Test set skorları\n",
    "scores_test = np.array([som_quantization_error(som, x) for x in X_test])\n",
    "\n",
    "# ROC-AUC ve PR-AUC (etikete göre)\n",
    "roc = roc_auc_score(y_test, scores_test)\n",
    "ap  = average_precision_score(y_test, scores_test)\n",
    "print(f\"SOM Anomaly Score -> ROC-AUC: {roc:.4f} | PR-AUC: {ap:.4f}\")\n",
    "\n",
    "# PR eğrisi / ROC eğrisi\n",
    "prec, rec, thr = precision_recall_curve(y_test, scores_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, scores_test)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\"); plt.grid(alpha=0.3)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall\"); plt.grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "```\n",
    "\n",
    "> **Not:** Fraud oranı **çok düşük** olduğu için **PR-AUC** özellikle anlamlıdır. ROC-AUC yüksek görünse bile PR-AUC düşük olabilir; bu normal.\n",
    "\n",
    "---\n",
    "\n",
    "# 9) Basit eşik seçimi (en anormal %k yakala)\n",
    "\n",
    "**Senaryo:** “En riskli %1”i alarm verelim gibi. Aşağıda **üst yüzdelik** ile eşik seçiyoruz.\n",
    "\n",
    "```python\n",
    "def topk_threshold(scores, top_ratio=0.01):\n",
    "    k = max(1, int(len(scores)*top_ratio))\n",
    "    return np.sort(scores)[-k]\n",
    "\n",
    "th = topk_threshold(scores_test, top_ratio=0.01)  # en anormal %1\n",
    "y_pred = (scores_test >= th).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "```\n",
    "\n",
    "> Bu yaklaşım **operasyonel** bir bakış: kuruma “günde en riskli şu kadar işlemi incele” dersen, **top-k** alarm pratik olur.\n",
    "\n",
    "---\n",
    "\n",
    "# 10) K-Means + Elbow (karşılaştırma amaçlı)\n",
    "\n",
    "**Neden?** Gözetimsiz bir referans yöntemle kıyas. K-Means kümelerinde **fraud oranlarına** da bakacağız.\n",
    "\n",
    "```python\n",
    "# Elbow grafiği (inertia)\n",
    "inertias, ks = [], range(2, 13)\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    km.fit(X_train)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.plot(ks, inertias, marker=\"o\")\n",
    "plt.title(\"K-Means Elbow (Inertia)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"inertia\"); plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Örnek bir k ile test kümeleri ve fraud oranları\n",
    "k = 8\n",
    "km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(X_train)\n",
    "test_labels = km.predict(X_test)\n",
    "\n",
    "# Her kümede fraud oranı\n",
    "fraud_rates = []\n",
    "for i in range(k):\n",
    "    idx = (test_labels == i)\n",
    "    if idx.sum() > 0:\n",
    "        fraud_rate = y_test[idx].mean()\n",
    "    else:\n",
    "        fraud_rate = np.nan\n",
    "    fraud_rates.append(fraud_rate)\n",
    "\n",
    "pd.DataFrame({\"cluster\": range(k), \"fraud_rate\": fraud_rates}).sort_values(\"fraud_rate\", ascending=False)\n",
    "```\n",
    "\n",
    "> Burada amaç, bazı kümelerin **fraud-yoğun** olduğunu görmek. SOM haritasında gördüğün **anomali adaları**, K-Means tarafında **yüksek fraud oranlı** 1–2 kümeye karşılık gelebilir.\n",
    "\n",
    "---\n",
    "\n",
    "## Mini rehber (ne oldu/niye oldu?)\n",
    "\n",
    "* **StandardScaler**: Tüm öznitelikleri benzer ölçeğe getirir → mesafe tabanlı (SOM/KMeans) yöntemler sağlıklı çalışır.\n",
    "* **PCA (opsiyonel)**: Gürültüyü azaltır, hız kazandırır; SOM’un stabilitesini artırır.\n",
    "* **SOM**: 2D grid üzerinde benzer örnekleri komşu hücrelere yerleştirir.\n",
    "\n",
    "  * **U-Matrix**: Hücre ağırlıkları arası mesafe ısı haritası (sınırlar/parçalanmalar = anomali sinyali).\n",
    "  * **Quantization error**: Örneğin BMU’suna uzaklığı = **anomali skoru**.\n",
    "* **ROC/PR**: SOM skoru ile gerçek etiketleri kıyaslar; PR özellikle dengesiz veri için anlamlıdır.\n",
    "* **Top-k eşik**: İşe alıştırması kolay bir alarm kuralı: “en anormal %x”.\n",
    "* **K-Means + Elbow**: Gözetimsiz referans; fraud oranlarıyla kümeleri yorumlayabilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "## Varyasyonlar (denemek istersen)\n",
    "\n",
    "* **SOM grid boyutu**: 15×15 / 25×25 dene; `sigma` ve iteration’ları biraz oyna.\n",
    "* **Anomaly skoru**: BMU uzaklığı yerine **BMU komşu ort. U-Matrix değeri** (veya BMU ağırlığı ile “local density”) de skora dönüştürülebilir.\n",
    "* **Sadece `Amount` ve `Time`’ı özel işle**: Log(Amount+1), zaman pencereleri vb. özellik mühendisliği ekleyebilirsin.\n",
    "* **Karşılaştırma algoritması**: Isolation Forest / LOF ekle (skorları PR-AUC ile kıyasla).\n",
    "\n",
    "---\n",
    "\n",
    "Hazırsan bu notebook’la çalış; grafik/sonuçlardan sonra “skoru nasıl iyileştiririz?” diye birlikte ince ayar yaparız (SOM hiperparametreleri, PCA oranı, top-k, vs.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3e777-a76a-4f32-a7fe-4e801d60819f",
   "metadata": {},
   "source": [
    "Güzel çalışma! Çıktıları birlikte okuyalım ve hızlı iyileştirmelerle “daha anlamlı” sonuçlar alalım.\n",
    "\n",
    "## Ne görüyoruz?\n",
    "\n",
    "* **ROC-AUC = 0.59, PR-AUC = 0.548** → ayırma gücü zayıf (pozitif oranı ≈0.44, yani PR-AUC tabanı ≈0.44; biraz üstü).\n",
    "* **Classification report**’ta `recall(1)=0.016` → neredeyse hiç fraud yakalanmamış. Bunun nedeni büyük olasılıkla **top-k eşiği**ni **%1** seçmen: 138 testten 1–2 örneği “anomali” saydı → **çok düşük recall**.\n",
    "* **K-Means** tabloda bazı kümelerin **çok yüksek fraud oranı** var (örn. cluster 0: 1.00). Bu, veri uzayında **fraud yoğun adacıklar** olduğunu gösteriyor – faydalanabiliriz.\n",
    "\n",
    "## Hızlı teşhis (nerede tıkanıyoruz?)\n",
    "\n",
    "1. **Feature set**: Paylaştığın tabloda **`CustomerID`** var. Bu **kimlik/anahtar** niteliği taşıyor; davranış bilgisi içermiyor. **Mutlaka çıkar.**\n",
    "2. **Boyut/ölçek**: 15 → 14 PCA kalmış; zaten düşük boyut. PCA’yı kapatıp sadece **StandardScaler** ile denemek çoğu kez daha iyi oluyor.\n",
    "3. **SOM ayarları**: `20×20` (400 hücre) **552 train** için **sparse** kalabilir. Daha kompakt bir harita genelde daha iyi ayrışıyor.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Kolay kazançlar: eşiği düzelt + kimlik sütununu at\n",
    "\n",
    "Varsayılan **top-k=1%** yerine, **PR eğrisinden** eşik seçelim (ör. **F1’i maksimize eden** ya da **Precision≥0.8** koşullu en yüksek recall).\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "\n",
    "# 1) CustomerID'yi düş\n",
    "X = df.drop(columns=[\"Class\", \"CustomerID\"])  # <— ÖNEMLİ\n",
    "y = df[\"Class\"].values.astype(int)\n",
    "\n",
    "# 2) Sadece StandardScaler kullan (PCA'yı kapatıp tekrar dene)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3) (Önceki SOM'u bu X_train ile yeniden eğit)\n",
    "# ... som = MiniSom(...); som.train_random(X_train, ...)\n",
    "\n",
    "# 4) QE skorları (test)\n",
    "scores_test = np.array([som_quantization_error(som, x) for x in X_test])\n",
    "\n",
    "# 5) F1-optimal eşik\n",
    "prec, rec, thr = precision_recall_curve(y_test, scores_test)\n",
    "f1s = 2*prec[:-1]*rec[:-1] / (prec[:-1]+rec[:-1] + 1e-12)\n",
    "t_star = thr[f1s.argmax()]\n",
    "y_pred = (scores_test >= t_star).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, scores_test))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, scores_test))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "```\n",
    "\n",
    "> Beklenti: **recall(1)** keskin biçimde artar, F1 toparlar. (Precision biraz düşebilir; bu bir **iş tercihi**.)\n",
    "\n",
    "İş ihtiyacına göre **Precision≥0.8** gibi bir hedef de koyabilirsin:\n",
    "\n",
    "```python\n",
    "target_p = 0.80\n",
    "idx = np.where(prec[:-1] >= target_p)[0]\n",
    "i = idx[np.argmax(rec[idx])] if len(idx) else f1s.argmax()\n",
    "t_star = thr[i]\n",
    "y_pred = (scores_test >= t_star).astype(int)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. SOM hiperparametreleri: haritayı “sıkılaştır”\n",
    "\n",
    "552 train örneği için şu kılavuz iyi işliyor:\n",
    "\n",
    "* **Harita boyutu:** `~12×12` veya `~15×15` (400 → 144/225’e düşür)\n",
    "* **Sigma:** 1.5–2.0\n",
    "* **Learning rate:** 0.5 → iterasyonla azaltma (MiniSom kendi azaltır)\n",
    "* **Iterasyon:** `~10–20 × N_train` (5× ile hızlı test, iyi durursa artır)\n",
    "\n",
    "```python\n",
    "m, n = 12, 12\n",
    "som = MiniSom(x=m, y=n, input_len=X_train.shape[1], sigma=1.8, learning_rate=0.5,\n",
    "              neighborhood_function='gaussian', random_seed=42)\n",
    "som.random_weights_init(X_train)\n",
    "som.train_random(X_train, 15*X_train.shape[0], verbose=True)\n",
    "```\n",
    "\n",
    "> Daha kompakt haritalar genelde **U-Matrix’te ayrımı** netleştirir, **QE skorunun** sinyalini güçlendirir.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. (Yarı denetimli) **BMU Fraud Yoğunluğu** skoru\n",
    "\n",
    "SOM unsupervised; ama **etiketleri sadece “skor fonksiyonu” öğrenmek için kullanabilirsin**:\n",
    "Her BMU hücresi için **train set fraud oranı**nı hesapla; testte o hücreye düşen örneğe bu oranı **anomaly/fraud skoru** olarak ver.\n",
    "\n",
    "```python\n",
    "# Train noktalarını hücrelere ata\n",
    "bmu_train = np.array([som.winner(x) for x in X_train])\n",
    "\n",
    "# Her hücrenin fraud oranını hesapla\n",
    "from collections import defaultdict\n",
    "cell_counts = defaultdict(int)\n",
    "cell_fraud  = defaultdict(int)\n",
    "for (cx, cy), lab in zip(bmu_train, y_train):\n",
    "    cell_counts[(cx, cy)] += 1\n",
    "    cell_fraud[(cx, cy)]  += int(lab)\n",
    "\n",
    "cell_rate = {k: (cell_fraud[k] / cell_counts[k]) for k in cell_counts.keys()}\n",
    "\n",
    "# Test için “fraud propensity score”\n",
    "bmu_test = np.array([som.winner(x) for x in X_test])\n",
    "propensity = np.array([cell_rate.get(tuple(c), 0.0) for c in bmu_test])  # görülmeyen hücreler 0\n",
    "\n",
    "print(\"BMU-propensity ROC-AUC:\", roc_auc_score(y_test, propensity))\n",
    "print(\"BMU-propensity PR-AUC :\", average_precision_score(y_test, propensity))\n",
    "```\n",
    "\n",
    "> Bu yaklaşım **K-Means küme fraud oranı** fikrine benzer ama **topolojik (SOM)** bir ağ üzerinde çalışır. Çoğu zaman **QE skorundan daha güçlü** olur.\n",
    "\n",
    "İstersen **iki skoru birleştir** (ör. `final_score = α*QE + (1-α)*propensity` ya da bir **logit regresyon** ile):\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "S = np.vstack([scores_test, propensity]).T\n",
    "clf = LogisticRegression().fit(S, y_test)  # (gerçekte train/valid ayrımı yap)\n",
    "final = clf.predict_proba(S)[:,1]\n",
    "print(\"Combo ROC-AUC:\", roc_auc_score(y_test, final))\n",
    "print(\"Combo PR-AUC :\", average_precision_score(y_test, final))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. K-Means ile karşılaştırmayı güçlendir\n",
    "\n",
    "K-Means tarafında yaptığın gibi **kümelerin fraud oranını** haritala ve bunu da **skor** olarak kullan:\n",
    "\n",
    "```python\n",
    "km = KMeans(n_clusters=8, n_init=10, random_state=42).fit(X_train)\n",
    "train_k = km.predict(X_train)\n",
    "test_k  = km.predict(X_test)\n",
    "\n",
    "# Küme fraud oranları (train)\n",
    "k_rates = {i: (y_train[train_k==i].mean() if (train_k==i).any() else 0.0)\n",
    "           for i in range(8)}\n",
    "\n",
    "k_score = np.array([k_rates[c] for c in test_k])\n",
    "print(\"KMeans-propensity ROC-AUC:\", roc_auc_score(y_test, k_score))\n",
    "print(\"KMeans-propensity PR-AUC :\", average_precision_score(y_test, k_score))\n",
    "```\n",
    "\n",
    "> Böylece **SOM-propensity** ile **K-Means-propensity**’yi kıyaslayıp, istersen **ensemble** (basit ortalama) yaparsın.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Son mini-checklist\n",
    "\n",
    "* [x] **`CustomerID`** gibi kimlik sütunlarını **at**\n",
    "* [x] PCA’yı **kapatıp** bir dene (sadece `StandardScaler`)\n",
    "* [x] SOM haritasını **12×12 / 15×15** yap, `sigma≈1.8`\n",
    "* [x] **Eşik seçimini** PR eğrisinden yap (**F1-opt** ya da **Precision≥x**)\n",
    "* [x] (İsteğe bağlı) **BMU fraud yoğunluğu** skoru + QE ile **birleştir**\n",
    "* [x] K-Means propensity ile **karşılaştır**; gerekiyorsa **ensemble**\n",
    "\n",
    "Bu düzeltmelerle PR-AUC ve (seçtiğin eşik stratejisine göre) F1/Recall belirgin şekilde artacaktır. Dilersen çıktını (yenilenen ROC/PR, report) at; birlikte ince ayarı (harita boyutu/σ/iterasyon) optimize edelim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a715a-0657-46c3-a3ab-1d890c598225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
