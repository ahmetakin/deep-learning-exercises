{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46da312-5264-4905-8ab9-64b80754c0f7",
   "metadata": {},
   "source": [
    "harika soru — “neden augmentation” ve “nasıl eklerim” konusunu **CIFAR-10** ve senin **Cats vs Dogs** koduna benzer bir kurgu üzerinden, adım adım bir mini-klavuz halinde vereyim. Aşağıda iki yol var:\n",
    "\n",
    "1. **Modern Keras yolu (önerilir):** `tf.keras.layers` ile modelin içine data augmentation katmanları\n",
    "2. **Klasik yol (senin videodaki gibi):** `ImageDataGenerator` ile dizin tabanlı akış\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Data Augmentation Nedir, Neden Gerekli?\n",
    "\n",
    "* **Amaç:** Eğitim verisini yapay olarak çeşitlendirip **genelleme** kabiliyetini artırmak, **overfit** riskini azaltmak.\n",
    "* **Nasıl:** Görüntülere rastgele fakat anlamı bozmayan dönüşümler uygularız (flip, crop, rotate, zoom, color jitter vs).\n",
    "* **Kural:** Augmentation **sadece** eğitim verisine uygulanır; **valid/test** verisine **uygulanmaz** (yalnızca `rescale`/normalize).\n",
    "\n",
    "---\n",
    "\n",
    "# 2) CIFAR-10 için önerilen modern yaklaşım\n",
    "\n",
    "CIFAR-10’u Keras’tan indiriyoruz, **modelin başına** augmentation katmanlarını koyuyoruz. Bu katmanlar **GPU’da** çalıştığı için hızlıdır ve **pipeline sade** kalır.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets, callbacks\n",
    "\n",
    "# 1) Veri: CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# 2) Data augmentation katmanları (Sadece TRAIN'de aktif)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),         # sağ-sol çevirme\n",
    "    layers.RandomRotation(0.05),             # ~±9 derece\n",
    "    layers.RandomZoom(0.1),                  # hafif zoom\n",
    "    layers.RandomTranslation(0.05, 0.05),    # x,y ekseninde kaydırma\n",
    "    # layers.RandomContrast(0.1),            # istersen kontrast\n",
    "])\n",
    "\n",
    "# 3) Basit bir CNN modeli (augmentation + normalize pipeline içeride)\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs, training=True)  # training=True sadece eğitimde uygular\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 4) Callbacks: EarlyStopping + ModelCheckpoint (en iyi ağırlıkları kaydet)\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", mode=\"max\", patience=7, restore_best_weights=True, verbose=1\n",
    ")\n",
    "ckpt = callbacks.ModelCheckpoint(\n",
    "    \"cifar10_cnn_aug_best.keras\", monitor=\"val_accuracy\", mode=\"max\",\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "# 5) Eğitim (validation_split ile val ayırıyoruz)\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=[es, ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6) Test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test acc:\", round(test_acc, 4))\n",
    "\n",
    "# 7) Modeli kaydet / yükle\n",
    "model.save(\"cifar10_cnn_aug_final.keras\")\n",
    "reloaded = tf.keras.models.load_model(\"cifar10_cnn_aug_best.keras\")\n",
    "print(\"Reloaded acc:\", reloaded.evaluate(x_test, y_test, verbose=0)[1])\n",
    "```\n",
    "\n",
    "> Notlar\n",
    ">\n",
    "> * `data_augmentation(..., training=True)` ifadesi, **eğitim** sırasında aktif, **inference** sırasında pasif olmasını sağlar.\n",
    "> * CIFAR-10 küçük (32×32). Aşırı güçlü augmentasyon (büyük rotate, çok zoom) **sinyali bozabilir**. Oranları küçük tut.\n",
    "> * Augmentation katmanları **modelin içinde** olduğundan, dışarıda `ImageDataGenerator` kullanmana gerek kalmaz.\n",
    "\n",
    "---\n",
    "\n",
    "# 3) “Video tarzı” **ImageDataGenerator** ile (Klasik Yol)\n",
    "\n",
    "Senin Cats vs Dogs kodunun birebir CIFAR-10 eşleniği dizin yapısı ister (ör: `cifar10/train/<class>/...`). CIFAR-10’u **dizin halinde** kullanmıyorsan, bu yol yerine **yukarıdaki modern yaklaşımı** seç.\n",
    "\n",
    "Yine de aynı mantığı göstereyim:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Sadece eğitimde güçlü augmentasyon; test/valid'de sadece rescale\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.1,  # train klasöründen %10'u valid olarak ayır\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_flow = train_gen.flow_from_directory(\n",
    "    \"data/cifar10/train\",         # klasör yapısı: data/cifar10/train/<class>/*.png\n",
    "    target_size=(32, 32),\n",
    "    batch_size=128,\n",
    "    class_mode=\"sparse\",          # 10 sınıf için sparse kullan\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_flow = train_gen.flow_from_directory(\n",
    "    \"data/cifar10/train\",\n",
    "    target_size=(32, 32),\n",
    "    batch_size=256,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_flow = test_gen.flow_from_directory(\n",
    "    \"data/cifar10/test\",          # test klasörü\n",
    "    target_size=(32, 32),\n",
    "    batch_size=256,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Model aynı kalabilir (augmentation bu kez jeneratörde)\n",
    "cnn = tf.keras.models.Sequential([\n",
    "    layers.Input((32,32,3)),\n",
    "    layers.Conv2D(32,3,activation='relu',padding='same'), layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64,3,activation='relu',padding='same'), layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128,3,activation='relu',padding='same'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(train_flow, validation_data=valid_flow, epochs=30)\n",
    "\n",
    "print(\"Test:\", cnn.evaluate(test_flow, verbose=0))\n",
    "```\n",
    "\n",
    "> **Hangisini seçmeliyim?**\n",
    ">\n",
    "> * **Keras katmanlarıyla augmentation (önerilir):** Daha modern, GPU-hızlı, kod sade.\n",
    "> * **ImageDataGenerator:** Dizin yapısı hazır projelerde pratik; fakat `preprocessing` API’si eski ve gelecekte yerini `tf.data` + preprocessing layers’a bırakıyor.\n",
    "\n",
    "---\n",
    "\n",
    "# 4) Cats vs Dogs koduna “neden/nerede augmentation?”\n",
    "\n",
    "Senin videodaki kodda augmentation **`train_datagen`** içinde, testte **sadece rescale** var. Bu **doğru pratik**. Aynısını CIFAR-10 için de yaptık.\n",
    "Kritik noktalar:\n",
    "\n",
    "* **Eğitim:** `RandomFlip/Rotation/Zoom/Shift/Shear/Contrast` gibi opsiyonlar\n",
    "* **Valid/Test:** Sadece `rescale` / normalize\n",
    "* **Aşırıya kaçma:** Küçük imgeler (32×32) için agresif dönüşümler modeli yanıltabilir.\n",
    "\n",
    "---\n",
    "\n",
    "# 5) Transfer Learning ile augmentation\n",
    "\n",
    "CIFAR-10’u **224×224**’e `tf.image.resize` ile büyütüp EfficientNet/ResNet gibi **ImageNet ön-eğitimli** iskelet kullanabilirsin. Augmentasyonu yine **katmanlarla** ekle:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "base = applications.EfficientNetB0(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=(224,224,3)\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "inputs = layers.Input((224,224,3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = data_augmentation(x, training=True)       # augmentation burada\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "tl_model = models.Model(inputs, outputs)\n",
    "tl_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "> **Not:** İleride **fine-tune** için `base.trainable = True` yapıp **küçük LR** ile birkaç üst bloğu açabilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "# 6) Tek görsel tahmini (CIFAR-10 boyutunda)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"some_image.png\", target_size=(32,32))\n",
    "x = image.img_to_array(img) / 255.0\n",
    "x = np.expand_dims(x, 0)  # (1, 32, 32, 3)\n",
    "\n",
    "proba = model.predict(x)\n",
    "pred  = np.argmax(proba, axis=1)[0]\n",
    "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "print(\"Pred:\", class_names[pred], \"Prob:\", round(float(np.max(proba)), 3))\n",
    "```\n",
    "\n",
    "> **Transfer Learning** yolunda hedef boyut **224×224** olacağından `target_size=(224,224)` kullan.\n",
    "\n",
    "---\n",
    "\n",
    "# 7) Hızlı kontrol listesi\n",
    "\n",
    "* [ ] Augmentation **yalnızca eğitim** verisine\n",
    "* [ ] Valid/test’te **sadece normalize**\n",
    "* [ ] Küçük imgede **hafif** dönüşümler\n",
    "* [ ] `EarlyStopping` + `ModelCheckpoint` ile **stabil eğitim**\n",
    "* [ ] **Model** ve **preprocess/label map** (gerekirse) **kaydet**\n",
    "* [ ] Tek görsel tahmininde **aynı ön-işleme** adımlarını uygula\n",
    "\n",
    "---\n",
    "\n",
    "istersen mevcut CNN kodunu **augmentation katmanlı** hale getirip **grafiklerle** (loss/acc) ve **confusion matrix** ekleyerek de güncelleyeyim; ya da Cats vs Dogs dizin yapın varsa **ImageDataGenerator** ile pub/sub tarzı daha modüler bir pipeline oluşturayım.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e6f42-c935-455e-a585-fa53b91197dd",
   "metadata": {},
   "source": [
    "kısa cevap: **hedefimiz “genelleme hatasını” (beklenen riski) düşürmek**. pratikte bu, **doğru loss’u minimize edip** aynı zamanda **işe uygun metrikleri (accuracy, F1, AUC, vb.) yüksek tutmak** demektir. ancak “en düşük *train* loss & en yüksek *train* accuracy” tek başına doğru hedef değildir — **asıl takip etmen gereken validation (ve en sonda test) metrikleridir.**\n",
    "\n",
    "## neden sadece “en düşük loss & en yüksek accuracy” demek yetmez?\n",
    "\n",
    "* **train vs validation:** modelin *train* değerleri doğal olarak çok iyi olur; önemli olan **validation/test** performansıdır. overfit’i ancak burada yakalarsın.\n",
    "* **loss vs accuracy farkı:**\n",
    "\n",
    "  * **Loss** (örn. cross-entropy) **olasılıkların kalitesini** cezalandırır; eşikten bağımsız ve diferansiye edilebilir (eğitilebilirlik için şart).\n",
    "  * **Accuracy** eşik (0.5 gibi) seçimine bağlı, olasılık kalibrasyonunu görmez; sınıf dengesizliğinde yanıltıcı olabilir.\n",
    "* **dengesiz veri:** accuracy yüksek görünüp **minor sınıfı** kaçırabilirsin. Bu durumda **F1, Recall, AUC-PR** daha anlamlı olabilir.\n",
    "* **çok sınıflı (CIFAR-10) senaryoda:** genelde **categorical cross-entropy** minimize edilir; raporlamada **top-1/top-5 accuracy** izlenir. AUC çok-sınıflıda ek kurgu ister.\n",
    "\n",
    "## pratik hedefleme (özet)\n",
    "\n",
    "* **Eğitimde optimize edilen:** uygun **loss** (binary için `binary_crossentropy`, çok-sınıf için `categorical_crossentropy`/`sparse_categorical_crossentropy`).\n",
    "* **İzlenen rapor metrikleri:** probleme göre `accuracy` + (gerekiyorsa) `Precision`, `Recall`, `F1`, `AUC`, `AUPRC`.\n",
    "* **Karar:** **validation** metriklerine göre model seç (en düşük `val_loss` veya en yüksek `val_accuracy`/`val_auc`).\n",
    "* **Test seti:** sadece final değerlendirme; **tuning yapma**.\n",
    "\n",
    "## hangi durumda hangi metriği öne alayım?\n",
    "\n",
    "* **Dengeli görüntü sınıflandırma (CIFAR-10):**\n",
    "\n",
    "  * Optimize: `categorical_crossentropy`\n",
    "  * Monitor: `val_accuracy` (ve `val_loss`)\n",
    "  * Kaydet: `ModelCheckpoint(monitor=\"val_accuracy\", save_best_only=True)` **veya** `monitor=\"val_loss\"`\n",
    "* **Dengesiz ikili sınıflandırma (injury):**\n",
    "\n",
    "  * Optimize: `binary_crossentropy`\n",
    "  * Monitor: `val_auc` **ve/veya** `val_f1` (F1’ı callback ile hesaplatabilirsin) ve `val_loss`\n",
    "  * Karar eşiği: sonradan **iş ihtiyacına** göre seç (precision/recall dengesi).\n",
    "\n",
    "## neden çoğu zaman `val_loss` daha güvenli?\n",
    "\n",
    "* `val_loss` **eşikten bağımsız** ve sürekli olduğundan küçük değişimleri daha erken yakalar; kalibrasyon ve belirsizlikle ilgili sinyali de taşır.\n",
    "* `val_accuracy` pratik ve anlaşılır, ama bazen **plateau** yaparken loss hâlâ iyileşiyor olabilir (olasılıklar daha iyi kalibre oluyor).\n",
    "\n",
    "## önerilen callback ve derleme iskeleti\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks, metrics\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # CIFAR-10 için\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        # ikili ise: metrics.AUC(name=\"auc\"), metrics.Precision(), metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",  # veya \"val_accuracy\" / \"val_auc\" probleme göre\n",
    "    mode=\"min\",          # val_accuracy/val_auc için \"max\"\n",
    "    patience=7,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ckpt = callbacks.ModelCheckpoint(\n",
    "    \"best.keras\",\n",
    "    monitor=\"val_loss\",  # veya \"val_accuracy\"/\"val_auc\"\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    callbacks=[es, ckpt]\n",
    ")\n",
    "```\n",
    "\n",
    "## sahada karar: hangi “en iyi” modeli seçmeli?\n",
    "\n",
    "* **Görüntü (CIFAR-10):** çoğunlukla **en yüksek `val_accuracy`** (eşlikçi olarak `val_loss` ve öğrenme eğrilerine bak).\n",
    "* **Dengesiz ikili:** çoğunlukla **en yüksek `val_auc`** veya **en düşük `val_loss`**; operasyonel eşik daha sonra **PR/ROC** eğrilerinden belirlenir.\n",
    "\n",
    "## kısacası\n",
    "\n",
    "* Amaç **genelleme** ⇒ **doğru loss’u minimize et**, **doğru metriği** maksimize et.\n",
    "* **Train** metrikleri değil, **Validation/Test** metrikleri esastır.\n",
    "* Hangi metriği “esas” alacağın **problemine** ve **maliyet fonksiyonuna** bağlıdır.\n",
    "* CIFAR-10 gibi dengeli çok-sınıfta: `val_accuracy` (+ `val_loss`).\n",
    "* Dengesiz ikili sınıfta: `val_auc`/`val_f1` (+ `val_loss`) ve **sonradan eşik seçimi**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d30068-0963-4c60-bfab-c2268af168b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
